{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa9ed5-01af-4441-92fb-56331ae10488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/usr/local/lib/python3.9/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/usr/local/lib/python3.9/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl5mutexC1Ev']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/usr/local/lib/python3.9/dist-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/usr/local/lib/python3.9/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/usr/local/lib/python3.9/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# import default libraries\n",
    "########################################################################\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "########################################################################\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# import additional libraries\n",
    "########################################################################\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "# from import\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    from sklearn.externals import joblib\n",
    "except:\n",
    "    import joblib\n",
    "# original lib\n",
    "import keras_model_doa\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import librosa as lb\n",
    "import keras.backend as K\n",
    "import common as com\n",
    "from __future__ import division \n",
    "import numpy as np\n",
    "import sys\n",
    "import cv2\n",
    "import keras_model_doa_ps\n",
    "from scipy.signal import butter,sosfilt,correlate2d\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow_io as tfio\n",
    "import keras_model_unet_1D\n",
    "import tensorflow_probability as tfp\n",
    "import math\n",
    "import keras_model_unet_crm\n",
    "import keras_model_uformer\n",
    "from scipy.interpolate import interp1d\n",
    "from feature_extractor import salsa\n",
    "############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d58f89a-ebd2-4249-9dcf-a2511b8b2013",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# load parameter.yaml\n",
    "########################################################################\n",
    "param = com.yaml_load()\n",
    "########################################################################\n",
    "saved_weight = os.path.join(param[\"P_MODELSAVE\"], 'dataweights.{epoch:02d}-{val_dense_1_binary_accuracy:.2f}.hdf5')\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor = 'val_mask_loss', patience = 10)\n",
    "# model_unet = keras_model.get_model(input_shape=(1,param[\"feature\"][\"n_mels\"],param[\"feature\"][\"n_frames\"]), lr = param[\"fit\"][\"lr\"])\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"PySoundFile failed. Trying audioread instead.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16daa170-5862-405b-a363-8eaac59eba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# get data from the list for file paths\n",
    "########################################################################\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    sos = butter(order, [low, high], analog=False, btype='band', output='sos')\n",
    "    return sos\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = sosfilt(sos, data)\n",
    "    return y\n",
    "\n",
    "def cal_rms(amp):\n",
    "    return tf.math.sqrt(tf.math.reduce_mean(tf.math.square(amp), axis=-1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    tf.print(K.square(y_pred - y_true))\n",
    "    return K.mean(K.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "def SALSA(audio, fs=22050, n_fft=1024, hop_length=345\n",
    "          , feature_type = 'salsa_lite'):\n",
    "    audio_input = audio.numpy()\n",
    "    # Compute stft\n",
    "    log_specs = []\n",
    "    n_mics = 4\n",
    "    n_bins = n_fft // 2 + 1\n",
    "    fmax = 6050  # Hz\n",
    "    fmin_doa = 520\n",
    "    fmax_doa = 6050\n",
    "    lower_bin = int(np.floor(fmin_doa * n_fft / np.float32(fs)))  # 512: 1; 256: 0\n",
    "    upper_bin = int(np.floor(fmax_doa * n_fft / np.float32(fs)))  # 9000Hz: 512: 192, 256: 96\n",
    "    cutoff_bin = int(np.floor(fmax * n_fft / np.float32(fs)))  # 9000 Hz, 512 nfft: cutoff_bin = 192\n",
    "    c = 343\n",
    "    delta = 2 * np.pi * fs / (n_fft * c)\n",
    "    freq_vector = np.arange(n_bins)\n",
    "    freq_vector[0] = 1\n",
    "    freq_vector = freq_vector[:, None, None]  # n_bins x 1 x 1\n",
    "    lower_bin = np.max((1, lower_bin))\n",
    "    testt = []\n",
    "    for imic in np.arange(n_mics):\n",
    "        stft = lb.stft(y=np.asfortranarray(audio_input[imic, :]), n_fft=n_fft, hop_length=hop_length,\n",
    "                            center=True, window='hann', pad_mode='reflect')\n",
    "        if imic == 0:\n",
    "            n_frames = stft.shape[1]\n",
    "            X = np.zeros((n_bins, n_frames, n_mics), dtype='complex')  # (n_bins, n_frames, n_mics)\n",
    "        X[:, :, imic] = stft\n",
    "        # Compute log linear power spectrum\n",
    "        spec = (np.abs(stft) ** 2).T\n",
    "        log_spec = np.expand_dims(spec, axis=0)\n",
    "        log_specs.append(log_spec)\n",
    "    log_specs = np.concatenate(log_specs, axis=0)  # (n_mics, n_frames, n_bins)\n",
    "\n",
    "    # Compute spatial feature\n",
    "    phase_vector = np.angle(X[:, :, 1:] * np.conj(X[:, :, 0, None]))\n",
    "    if feature_type == 'salsa_ipd':\n",
    "        phase_vector = phase_vector / np.pi\n",
    "    elif feature_type == 'salsa_lite':\n",
    "        phase_vector = phase_vector / (delta * freq_vector)\n",
    "    phase_vector = np.transpose(phase_vector, (2, 1, 0))  # (n_mics, n_frames, n_bins)\n",
    "    # Crop frequency\n",
    "    log_specs = log_specs[:, :, lower_bin:cutoff_bin]\n",
    "    phase_vector = phase_vector[:, :, lower_bin:cutoff_bin]\n",
    "    phase_vector[:, :, upper_bin:] = 0\n",
    "    # Stack features\n",
    "    audio_feature = np.concatenate((log_specs, phase_vector), axis=0)\n",
    "    return audio_feature\n",
    "\n",
    "class MelSpecGccExtractor():\n",
    "    \"\"\"\n",
    "    Extract log-mel spectrograms and GCC-PHAT features.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        :param fs: Sampling rate.\n",
    "        :param n_fft: Number of FFT points.\n",
    "        :param hop_length: Number of sample for hopping.\n",
    "        :param n_mels: Number of mel bands.\n",
    "        :param win_length: Window length <= n_fft. If None, assign n_fft\n",
    "        :param fmin: Min frequency to extract feature (Hz).\n",
    "        :param fmax: Max frequency to extract feature (Hz).\n",
    "        :param window: Type of window.\n",
    "        \"\"\"\n",
    "        self.n_mels = 256\n",
    "        self.fs = 22050\n",
    "        self.window = \"hann\"\n",
    "        self.n_fft = 2048\n",
    "        self.hop_length = 345\n",
    "        self.win_length = None\n",
    "        self.fmin = 50\n",
    "        self.fmax = None\n",
    "        self.melW = lb.filters.mel(sr=self.fs, n_fft=self.n_fft, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax)\n",
    "\n",
    "    def gcc_phat(self, sig, refsig) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute GCC-PHAT between sig and refsig.\n",
    "        :param sig: <np.ndarray: (n_samples,).\n",
    "        :param refsig: <np.ndarray: (n_samples,).\n",
    "        :return: gcc_phat: <np.ndarray: (1, n_frames, n_mels)>\n",
    "        \"\"\"\n",
    "        ncorr = 2 * self.n_fft - 1\n",
    "        n_fft = int(2 ** np.ceil(np.log2(np.abs(ncorr))))  # this n_fft double the length of win_length\n",
    "        Px = lb.stft(y=np.asfortranarray(sig),\n",
    "                          n_fft=n_fft,\n",
    "                          hop_length=self.hop_length,\n",
    "                          win_length=self.win_length,\n",
    "                          center=True,\n",
    "                          window=self.window,\n",
    "                          pad_mode='reflect')\n",
    "        Px_ref = lb.stft(y=np.asfortranarray(refsig),\n",
    "                              n_fft=n_fft,\n",
    "                              hop_length=self.hop_length,\n",
    "                              win_length=self.win_length,\n",
    "                              center=True,\n",
    "                              window=self.window,\n",
    "                              pad_mode='reflect')\n",
    "        freq_filter = np.ones((n_fft//2 + 1, 1))\n",
    "        k_cutoff = int(4000 / self.fs * n_fft)\n",
    "        k_buffer = int(400 / self.fs * n_fft)\n",
    "        cos_x = np.arange(2 * k_buffer) * (np.pi/2) / (2 * k_buffer - 1)\n",
    "        freq_filter[k_cutoff - k_buffer: k_cutoff + k_buffer, 0] = np.cos(cos_x)\n",
    "        Px = Px * freq_filter\n",
    "        Px_ref = Px_ref * freq_filter\n",
    "\n",
    "        R = Px * np.conj(Px_ref)\n",
    "        n_frames = R.shape[1]\n",
    "        gcc_phat = []\n",
    "        for i in range(n_frames):\n",
    "            spec = R[:, i].flatten()\n",
    "            cc = np.fft.irfft(np.exp(1.j * np.angle(spec)))\n",
    "            cc = np.concatenate((cc[-self.n_mels // 2:], cc[:self.n_mels // 2]))\n",
    "            gcc_phat.append(cc)\n",
    "        gcc_phat = np.array(gcc_phat)\n",
    "        gcc_phat = gcc_phat[None, :, :]\n",
    "        return gcc_phat\n",
    "\n",
    "    def logmel(self, sig) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute logmel of single channel signal\n",
    "        :param sig: <np.ndarray: (n_samples,).\n",
    "        :return: logmel: <np.ndarray: (1, n_frames, n_mels)>.\n",
    "        \"\"\"\n",
    "        spec = np.abs(lb.stft(y=np.asfortranarray(sig),\n",
    "                                   n_fft=self.n_fft,\n",
    "                                   hop_length=self.hop_length,\n",
    "                                   win_length=self.win_length,\n",
    "                                   center=True,\n",
    "                                   window=self.window,\n",
    "                                   pad_mode='reflect'))\n",
    "\n",
    "        mel_spec = np.dot(self.melW, spec ** 2).T\n",
    "        logmel_spec = lb.power_to_db(mel_spec, ref=1.0, amin=1e-10, top_db=None)\n",
    "        logmel_spec = np.expand_dims(logmel_spec, axis=0)\n",
    "\n",
    "        return logmel_spec\n",
    "\n",
    "    def extract(self, audio_input: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        :param audio_input: <np.ndarray: (n_channels, n_samples)>.\n",
    "        :return: features <np.ndarray: (n_channel + n_channels*(n_channel-1)/2, n_timeframes, n_features)>.\n",
    "        \"\"\"\n",
    "        n_channels = audio_input.shape[0]\n",
    "        features = []\n",
    "        gcc_features = []\n",
    "        for n in range(n_channels):\n",
    "            features.append(self.logmel(audio_input[n]))\n",
    "            for m in range(n + 1, n_channels):\n",
    "                gcc_features.append(self.gcc_phat(sig=audio_input[m], refsig=audio_input[n]))\n",
    "\n",
    "        features.extend(gcc_features)\n",
    "        features = np.concatenate(features, axis=0)\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b685187-6e8f-4f91-a464-e34b1046e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_corr(data1):\n",
    "    horizontal = correlate2d(data1[0], data1[1], mode='same')\n",
    "    vertical = correlate2d(data1[3], data1[2], mode='same')\n",
    "    horizontal = tf.expand_dims(horizontal, 0)\n",
    "    vertical = tf.expand_dims(vertical, 0)\n",
    "    cross = tf.concat([horizontal, vertical], axis = 0)\n",
    "    return cross\n",
    "\n",
    "def power_to_db(S, amin=1e-16, top_db=80.0):\n",
    "    \"\"\"Convert a power-spectrogram (magnitude squared) to decibel (dB) units.\n",
    "    Computes the scaling ``10 * log10(S / max(S))`` in a numerically\n",
    "    stable way.\n",
    "    Based on:\n",
    "    https://librosa.github.io/librosa/generated/librosa.core.power_to_db.html\n",
    "    \"\"\"\n",
    "    def _tf_log10(x):\n",
    "        numerator = tf.math.log(x)\n",
    "        denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
    "        return numerator / denominator\n",
    "    \n",
    "    # Scale magnitude relative to maximum value in S. Zeros in the output \n",
    "    # correspond to positions where S == ref.\n",
    "    ref = tf.reduce_max(S)\n",
    "\n",
    "    log_spec = 10.0 * _tf_log10(tf.maximum(amin, S))\n",
    "    log_spec -= 10.0 * _tf_log10(tf.maximum(amin, ref))\n",
    "\n",
    "    log_spec = tf.maximum(log_spec, tf.reduce_max(log_spec) - top_db)\n",
    "\n",
    "    return log_spec\n",
    "\n",
    "\n",
    "# AZIMUTH\n",
    "def readcsv(item):\n",
    "    df = pd.read_csv(item.numpy().decode())\n",
    "    x_ = (tf.cast(df[\"x_128\"][:128].astype('float32'), tf.float32))\n",
    "    # df[\"y_128\"][:128].astype('float32')\n",
    "    # df.loc[df[\"y_128\"] < 0, \"y_128\"].astype('float32')*-1\n",
    "    y_ = tf.cast((df[\"y_128\"][:128].astype('float32')), tf.float32)\n",
    "    \n",
    "    label_ = []\n",
    "    for n in df[\"label_128\"][:128]:\n",
    "        label_.append(tf.one_hot(int(n), 4))\n",
    "    label_ = tf.stack(label_)\n",
    "    return x_, y_, label_\n",
    "\n",
    "\n",
    "\n",
    "def band(data):\n",
    "    return butter_bandpass_filter(data.numpy(), 750, 22050/2-5, 22050)\n",
    "\n",
    "def mel_band(data):\n",
    "    bandpass = butter_bandpass_filter(data.numpy(), 750, 22050/2-5, 22050)\n",
    "    mel_spec = lb.feature.melspectrogram(y=bandpass, n_fft=1024, hop_length=320, n_mels=128, center=False, fmin=0,\n",
    "                                                fmax=22050/2)\n",
    "    return mel_spec\n",
    "\n",
    "\n",
    "def test_predict(data):\n",
    "    return model.predict(data)\n",
    "\n",
    "######\n",
    "# SALSA\n",
    "######\n",
    "@tf.function\n",
    "def file_read_doa(combined_path, direction, model = keras_model_uformer.wave_u_net(num_initial_filters = 64, num_layers = 4, \n",
    "           source_names = [\"siren\"], num_channels = 4, output_filter_size = 1,\n",
    "           padding = \"same\", input_size = 44100, context = False, upsampling_type = \"direct\",\n",
    "           output_activation = \"tanh\", output_type = \"direct\"),\n",
    "            part=0):\n",
    "    \"\"\"\n",
    "    convert file_name to a vector array.\n",
    "\n",
    "    file_name : str\n",
    "        target .wav file\n",
    "\n",
    "    return : numpy.array( numpy.array( float ) )\n",
    "        vector array\n",
    "        * dataset.shape = (dataset_size, feature_vector_length)\n",
    "    \"\"\"\n",
    "\n",
    "    # generate combined audio data using tf.io\n",
    "    model.load_weights(\"unet_model_1D/parts/new_conformer_mic_com_top_024.h5\")\n",
    "    combined_contents = tf.io.read_file(combined_path)\n",
    "    combined, sr = tf.audio.decode_wav(combined_contents)\n",
    "    combined = tf.unstack(combined, axis=-1, num=4)\n",
    "    dic = {\"1\": [0, 1, 2, 3], \"2\": [2, 1, 0, 3], \"3\": [2, 3, 0, 1], \"4\": [0, 3, 2, 1]}\n",
    "    combined   = tf.stack([combined[dic[part][0]], combined[dic[part][1]], combined[dic[part][2]], combined[dic[part][3]]], axis=-1)\n",
    "    combined = tf.transpose(tf.py_function(band, [tf.transpose(combined)], (tf.float32)))\n",
    "    combined = tf.reshape(combined , [1,tf.shape(combined)[0], tf.shape(combined)[1]])  \n",
    "    combined = tf.py_function(model, [combined[:, :, :]], (tf.float32))    \n",
    "    combined = tf.squeeze(tf.transpose(combined))\n",
    "    combined = tf.py_function(band, [combined], (tf.float32))\n",
    "    features = tf.py_function(SALSA, [combined], (tf.float32))\n",
    "    features = tf.reshape(features , [tf.shape(features)[0], tf.shape(features)[1], tf.shape(features)[2]])  \n",
    "    features = tf.transpose(features)\n",
    "    log = features[:,:,:4]\n",
    "    salsa = features[:,:,4:]\n",
    "    \n",
    "    onehot_f = power_to_db(log[:,:,0], top_db=80)\n",
    "    onehot = tf.math.reduce_max(onehot_f, 0)\n",
    "    \n",
    "    onehot = tf.where(tf.math.less_equal(onehot, -20), 0., onehot)\n",
    "    onehot = tf.where(tf.math.not_equal(onehot, 0), 1., onehot)\n",
    "    onehot_1 = tf.repeat(tf.expand_dims(onehot, 1), 4, 1)\n",
    "    onehot_ = tf.repeat(tf.expand_dims(onehot, 0), 256, 0)\n",
    "    onehot_2 = tf.repeat(tf.expand_dims(onehot_, -1), 3, -1)\n",
    "    onehot_3 = tf.repeat(tf.expand_dims(onehot_, -1), 4, -1)\n",
    "    \n",
    "    onehot_4 = tf.repeat(tf.expand_dims(onehot, -1), 2, -1)\n",
    "    onehot = onehot\n",
    "    \n",
    "    log = power_to_db(log*onehot_3, top_db=80)\n",
    "    salsa = salsa*onehot_2\n",
    "    features = tf.concat([log, salsa], -1)\n",
    "    dic2 = {\"1\":[1, 1], \"2\":[-1, 1], \"3\":[-1, -1], \"4\":[1, 1]}\n",
    "    \n",
    "    x, y, label_ =  tf.py_function(readcsv, [direction], (tf.float32,tf.float32,tf.float32))\n",
    "\n",
    "    label_ = tf.reshape(label_ , [128, 4])\n",
    "    inactive = tf.reduce_max(label_, 1)\n",
    "    \n",
    "    x_ = x*inactive*dic2[part][0]\n",
    "    y_ = y*inactive*dic2[part][1]\n",
    "\n",
    "    xy_dir = tf.stack([x_, y_, inactive], axis=1)\n",
    "    return features, {'doa_out':xy_dir, 'sed_out':label_}\n",
    "\n",
    "\n",
    "######\n",
    "# GCC PHAT\n",
    "#####\n",
    "# @tf.function\n",
    "# def file_read_doa(combined_path, direction, model = keras_model_unet_crm.model(input_size = (4, 44100)), part=0):\n",
    "#     \"\"\"\n",
    "#     convert file_name to a vector array.\n",
    "\n",
    "#     file_name : str\n",
    "#         target .wav file\n",
    "\n",
    "#     return : numpy.array( numpy.array( float ) )\n",
    "#         vector array\n",
    "#         * dataset.shape = (dataset_size, feature_vector_length)\n",
    "#     \"\"\"\n",
    "#     model.load_weights(\"unet_model_orm/dcunet_stft_mic1_074.h5\")\n",
    "#     # generate combined audio data using tf.io\n",
    "#     extract_feature =  MelSpecGccExtractor()\n",
    "#     combined_contents = tf.io.read_file(combined_path)\n",
    "#     combined, sr = tf.audio.decode_wav(combined_contents)\n",
    "#     combined = tf.unstack(combined, axis=-1, num=4)\n",
    "#     dic = {\"1\": [0, 1, 2, 3], \"2\": [1, 0, 2, 3], \"3\": [1, 0, 3, 2], \"4\": [0, 1, 3, 2]}\n",
    "#     # denoised   = tf.stack([combined[dic[part][0]], combined[dic[part][1]]], axis=-1)\n",
    "#     combined   = tf.stack([combined[dic[part][0]], combined[dic[part][1]], combined[dic[part][2]], combined[dic[part][3]]], axis=-1)\n",
    "\n",
    "#     combined = tf.py_function(band, [tf.transpose(combined)], (tf.float32))\n",
    "#     combined = tf.reshape(combined , [1,tf.shape(combined)[0], tf.shape(combined)[1]])  \n",
    "#     # max_ = tf.math.reduce_max(tf.abs(combined))\n",
    "#     # combined = tf.math.divide(combined,max_)\n",
    "\n",
    "#     denoised = tf.py_function(model, [combined], (tf.float32))    \n",
    "#     denoised = tf.squeeze(denoised)\n",
    "#     # denoised = combined\n",
    "#     denoised = tf.py_function(band, [tf.transpose(denoised)], (tf.float32))\n",
    "#     features = tf.py_function(extract_feature.extract, [denoised], (tf.float32))\n",
    "#     features = tf.reshape(features , [tf.shape(features)[0], tf.shape(features)[1], tf.shape(features)[2]])  \n",
    "#     features = tf.transpose(features)\n",
    "    \n",
    "#     # x_, y_, label_ =  tf.py_function(readcsv, [direction], (tf.float32,tf.float32,tf.float32))\n",
    "#     # x_ = tf.reshape(x_ , [128]) \n",
    "#     # y_ = tf.reshape(y_ , [128]) \n",
    "#     # label_ = tf.reshape(label_ , [128, 4])\n",
    "#     # xy_dir = tf.stack([x_, y_, tf.reduce_max(label_, 1)], axis=1)\n",
    "#     # return features, {'doa_out':xy_dir[32*part:32*part+32,:], 'sed_out':label_[32*part:32*part+32,:]}\n",
    "    \n",
    "# #     dir_, label_ =  tf.py_function(readcsv, [direction], (tf.float32,tf.float32))\n",
    "# #     dir_ = tf.reshape(dir_ , [128, 37]) \n",
    "# #     label_ = tf.reshape(label_ , [128, 4])\n",
    "    \n",
    "# #     return features, {'doa_out':dir_[32*part:32*part+32,:], 'sed_out':label_[32*part:32*part+32,:]}\n",
    "\n",
    "#     dir_, label_ =  tf.py_function(readcsv, [direction], (tf.float32,tf.float32))\n",
    "#     dic2 = {\"1\":[1, 1], \"2\":[-1, 1], \"3\":[-1, 1], \"4\":[1, -1]}\n",
    "#     label_ = tf.reshape(label_ , [128, 4])\n",
    "#     x_ = tf.math.cos(dir_)*tf.reduce_max(label_, 1)*dic2[part][0]\n",
    "#     y_ = tf.math.sin(dir_)*tf.reduce_max(label_, 1)*dic2[part][1]\n",
    "    \n",
    "    \n",
    "#     xy_dir = tf.stack([x_, y_, tf.reduce_max(label_, 1)], axis=1)\n",
    "    \n",
    "#     return tf.transpose(features), {'doa_out':xy_dir, 'sed_out':label_}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######\n",
    "# GCC\n",
    "######\n",
    "\n",
    "\n",
    "# @tf.function\n",
    "# def file_read_doa(combined_path, direction, part=0, n =0):\n",
    "#     \"\"\"\n",
    "#     convert file_name to a vector array.\n",
    "\n",
    "#     file_name : str\n",
    "#         target .wav file\n",
    "\n",
    "#     return : numpy.array( numpy.array( float ) )\n",
    "#         vector array\n",
    "#         * dataset.shape = (dataset_size, feature_vector_length)\n",
    "#     \"\"\"\n",
    "#     # model = keras_model_uformer.wave_u_net(num_initial_filters = 64, num_layers = 4, \n",
    "#     #        source_names = [\"siren\"], num_channels = 4, output_filter_size = 1,\n",
    "#     #        padding = \"same\", input_size = 44100, context = False, upsampling_type = \"direct\",\n",
    "#     #        output_activation = \"tanh\", output_type = \"direct\")\n",
    "#     # model.summary()\n",
    "#     # model.load_weights(\"unet_model_1D/parts/new_conformer_030.h5\")\n",
    "    \n",
    "#     # generate combined audio data using tf.io\n",
    "#     combined_contents = tf.io.read_file(combined_path)\n",
    "#     combined, sr = tf.audio.decode_wav(combined_contents)\n",
    "#     combined = tf.unstack(combined, axis=-1, num=4)\n",
    "#     dic = {\"1\": [0, 1, 2, 3], \"2\": [1, 0, 2, 3], \"3\": [1, 0, 3, 2], \"4\": [0, 1, 3, 2]}\n",
    "#     combined   = tf.stack([combined[dic[part][0]], combined[dic[part][1]], combined[dic[part][2]], combined[dic[part][3]]], axis=-1)\n",
    "    \n",
    "#     combined_mel = tf.py_function(mel_band, [tf.transpose(combined)[:,11025*n:11025*(n+1)]], (tf.float32))\n",
    "#     # combined_mel = tf.transpose(combined_mel)\n",
    "# #     combined_mel = tf.reshape(combined_mel , [1,tf.shape(combined_mel)[1], tf.shape(combined_mel)[0], tf.shape(combined_mel)[2]])  \n",
    "\n",
    "# #     # combined_mel = tf.reshape(combined_mel , [1,tf.shape(combined_mel)[1], tf.shape(combined_mel)[2], tf.shape(combined_mel)[0]])  \n",
    "# #     mask = tf.py_function(model, [combined_mel], (tf.float32))    \n",
    "# #     mask = tf.squeeze(mask)\n",
    "# #     combined_mel = tf.squeeze(combined_mel)\n",
    "# #     denoised_mel = (mask*combined_mel)\n",
    "# #     denoised_mel = tf.transpose(denoised_mel)\n",
    "#     cross_correlation = tf.py_function(cross_corr, [combined_mel], (tf.float32))   \n",
    "#     cross_correlation = tf.reshape(cross_correlation, [tf.shape(cross_correlation)[0], tf.shape(cross_correlation)[1], tf.shape(cross_correlation)[2]]) \n",
    "#     denoised_mel = tf.concat([combined_mel, cross_correlation], axis=0)        \n",
    "#     # denoised_mel = tfio.audio.dbscale(denoised_mel, top_db=80)\n",
    "#     denoised_mel = tfio.audio.dbscale(denoised_mel, top_db=100)\n",
    "#     denoised_mel = tf.transpose(denoised_mel)\n",
    "    \n",
    "#     dir_, label_ =  tf.py_function(readcsv, [direction], (tf.float32,tf.float32))\n",
    "#     dic2 = {\"1\":[1, 1], \"2\":[-1, 1], \"3\":[-1, 1], \"4\":[1, -1]}\n",
    "#     label_ = tf.reshape(label_ , [128, 4])\n",
    "#     x_ = tf.math.cos(dir_)*tf.reduce_max(label_, 1)*dic2[part][0]\n",
    "#     y_ = tf.math.sin(dir_)*tf.reduce_max(label_, 1)*dic2[part][1]\n",
    "    \n",
    "    \n",
    "#     xy_dir = tf.stack([x_, y_, tf.reduce_max(label_, 1)], axis=1)\n",
    "    \n",
    "#     return tf.transpose(denoised_mel), {'doa_out':xy_dir[::2,:][::2,:][::2,:][4*n:4*(n+1),:], 'sed_out':label_[::2,:][::2,:][::2,:][4*n:4*(n+1),:]}\n",
    "\n",
    "#     # x_, y_, label_ =  tf.py_function(readcsv, [direction], (tf.float32,tf.float32,tf.float32))\n",
    "\n",
    "#     # x_ = tf.reshape(x_ , [128]) \n",
    "#     # y_ = tf.reshape(y_ , [128]) \n",
    "#     # label_ = tf.reshape(label_ , [128, 4])\n",
    "#     # xy_dir = tf.stack([x_, y_, tf.reduce_max(label_, 1)], axis=1)\n",
    "#     # return tf.transpose(denoised_mel, [1,0,2]), {'doa_out':xy_dir, 'sed_out':label_}\n",
    "# #     dir_, label_ =  tf.py_function(readcsv, [direction], (tf.float32,tf.float32))\n",
    "# #     dir_ = tf.reshape(dir_ , [128, 37]) \n",
    "# #     label_ = tf.reshape(label_ , [128, 4])\n",
    "    \n",
    "# #     return denoised_mel, {'doa_out':dir_, 'sed_out':label_}\n",
    "\n",
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2abdd3-0a8e-4cd0-8c38-b754e20cd01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6697\n",
      "                                          combined_name  \\\n",
      "0     dev_data_doa/combined_ground_truth_topm_real/t...   \n",
      "1     dev_data_doa/combined_ground_truth_topm_real/t...   \n",
      "2     dev_data_doa/combined_ground_truth_topm_real/t...   \n",
      "3     dev_data_doa/combined_ground_truth_topm_real/t...   \n",
      "4     dev_data_doa/combined_ground_truth_topm_real/t...   \n",
      "...                                                 ...   \n",
      "6692  dev_data_doa/combined_ground_truth_topm_real/t...   \n",
      "6693  dev_data_doa/combined_ground_truth_topm_real/t...   \n",
      "6694  dev_data_doa/combined_ground_truth_topm_real/t...   \n",
      "6695  dev_data_doa/combined_ground_truth_topm_real/t...   \n",
      "6696  dev_data_doa/combined_ground_truth_topm_real/t...   \n",
      "\n",
      "                              anomaly_name                   snr  label  \\\n",
      "0     Crash-05_case_7_crash_Velocity_60kmh  [-29, -25, -32, -25]      0   \n",
      "1     Crash-05_case_7_crash_Velocity_60kmh  [-24, -24, -23, -23]      0   \n",
      "2     Crash-05_case_3_crash_Velocity_40kmh      [-4, -4, -3, -2]      0   \n",
      "3     Crash-05_case_3_crash_Velocity_40kmh    [-10, -11, -9, -9]      0   \n",
      "4     Crash-05_case_6_crash_Velocity_15kmh  [-17, -12, -12, -12]      0   \n",
      "...                                    ...                   ...    ...   \n",
      "6692    Skid-24_case_9_skid_Velocity_60kmh      [13, 12, 13, 14]      3   \n",
      "6693    Skid-24_case_1_skid_Velocity_60kmh      [-7, -8, -7, -6]      3   \n",
      "6694    Skid-24_case_1_skid_Velocity_60kmh         [-3, 0, 0, 1]      3   \n",
      "6695    Skid-24_case_9_skid_Velocity_30kmh     [-10, -1, -6, -1]      3   \n",
      "6696    Skid-24_case_9_skid_Velocity_30kmh       [-6, -1, -5, 0]      3   \n",
      "\n",
      "                                              direction  \n",
      "0     dev_data_doa/direction_ground_truth_top/train_...  \n",
      "1     dev_data_doa/direction_ground_truth_top/train_...  \n",
      "2     dev_data_doa/direction_ground_truth_top/train_...  \n",
      "3     dev_data_doa/direction_ground_truth_top/train_...  \n",
      "4     dev_data_doa/direction_ground_truth_top/train_...  \n",
      "...                                                 ...  \n",
      "6692  dev_data_doa/direction_ground_truth_top/train_...  \n",
      "6693  dev_data_doa/direction_ground_truth_top/train_...  \n",
      "6694  dev_data_doa/direction_ground_truth_top/train_...  \n",
      "6695  dev_data_doa/direction_ground_truth_top/train_...  \n",
      "6696  dev_data_doa/direction_ground_truth_top/train_...  \n",
      "\n",
      "[6697 rows x 5 columns]\n",
      "\n",
      "===========================\n",
      "============== DATASET_GENERATOR ==============\n",
      "tf.Tensor(6697, shape=(), dtype=int64)\n",
      "tf.Tensor(26, shape=(), dtype=int64) tf.Tensor(156, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#################### Dataset Load #############################################\n",
    "type_ = \"topm_real\"\n",
    "\n",
    "combined_loc = f\"dev_data_doa/combined_ground_truth_topm_real/train_noise/\"\n",
    "combined_loc_test = f\"dev_data_doa/combined_ground_truth_topm_real/test/\"\n",
    "\n",
    "dir_loc = f\"dev_data_doa/direction_ground_truth_top/train_new/\"\n",
    "\n",
    "dir_loc_test = f\"dev_data_doa/direction_ground_truth_top/test_new/\"\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(f\"dev_data_doa/combined_ground_truth_topm_real/train_noise_combined_extra.csv\")\n",
    "jk = pd.read_csv(f\"dev_data_doa/combined_ground_truth_topm_real/val_combined_extra.csv\")\n",
    "\n",
    "\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "\n",
    "\n",
    "df['combined_name'] = combined_loc + df['combined_name'].astype(str)\n",
    "df['direction'] = dir_loc + df['anomaly_name'].astype(str) + \"_direction.csv\"\n",
    "\n",
    "\n",
    "\n",
    "jk['combined_name'] = combined_loc_test + jk['combined_name'].astype(str)\n",
    "jk['direction'] = dir_loc_test + jk['anomaly_name'].astype(str) + \"_direction.csv\"\n",
    "\n",
    "\n",
    "jk = pd.concat([jk], ignore_index=True)\n",
    "jk = jk.loc[:, ~jk.columns.str.contains('^Unnamed')]\n",
    "jk = jk.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "jk_clean_test = jk.pop('combined_name')\n",
    "jk_dir_test = jk.pop('direction')\n",
    "\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df = df.dropna()\n",
    "\n",
    "print(df)\n",
    "\n",
    "\n",
    "df_clean_train = df.pop('combined_name')\n",
    "df_dir_train = df.pop('direction')\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n===========================\")\n",
    "\n",
    "print(\"============== DATASET_GENERATOR ==============\")\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((df_clean_train, df_dir_train))\n",
    "\n",
    "print(train_dataset.cardinality())\n",
    "\n",
    "\n",
    "data_train1 = train_dataset.map(lambda x,y: file_read_doa(x,y, part=\"1\"))\n",
    "data_train2 = train_dataset.map(lambda x,y: file_read_doa(x,y, part=\"2\"))\n",
    "data_train3 = train_dataset.map(lambda x,y: file_read_doa(x,y, part=\"3\"))\n",
    "\n",
    "data_train = data_train1.concatenate(data_train2).concatenate(data_train3).cache(\"tmp1/cache\").shuffle(16256).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((jk_clean_test, jk_dir_test))\n",
    "val_dataset = val_dataset\n",
    "data_val1 = val_dataset.map(lambda x,y: file_read_doa(x,y, part=\"1\"))\n",
    "\n",
    "data_val = data_val1.cache(\"tmp_doa2/cache\").batch(32).shuffle(100)\n",
    "                                                                                        \n",
    "\n",
    "print(data_val.cardinality(), data_train.cardinality())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3718a324-e2cb-4454-9a12-889834f8341f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "============== MODEL TRAINING ==============\n",
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 128, 7  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 128, 12  8192        ['input_1[0][0]']                \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256, 128, 12  512        ['conv2d[0][0]']                 \n",
      " alization)                     8)                                                                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 256, 128, 12  0           ['batch_normalization[0][0]']    \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 32, 128, 128  0           ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 32, 128, 128  0           ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 128, 128  147584      ['dropout_12[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 128, 128  512        ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 32, 128, 128  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 4, 128, 128)  0          ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 4, 128, 128)  0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 4, 128, 128)  147584      ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 4, 128, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 4, 128, 128)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 1, 128, 128)  0          ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 1, 128, 128)  0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " permute (Permute)              (None, 128, 1, 128)  0           ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 128, 128)     0           ['permute[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 128, 128)     198144      ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 128, 128)    198144      ['bidirectional[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 128, 128)    16512       ['bidirectional_1[0][0]']        \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      " time_distributed_2 (TimeDistri  (None, 128, 128)    16512       ['bidirectional_1[0][0]']        \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 128, 128)     0           ['time_distributed[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 128, 128)     0           ['time_distributed_2[0][0]']     \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, 128, 2)      258         ['dropout_15[0][0]']             \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDistri  (None, 128, 4)      516         ['dropout_16[0][0]']             \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " doa_out (Activation)           (None, 128, 2)       0           ['time_distributed_1[0][0]']     \n",
      "                                                                                                  \n",
      " sed_out (Activation)           (None, 128, 4)       0           ['time_distributed_3[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 734,982\n",
      "Trainable params: 734,214\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-23 23:25:23.555504: W tensorflow/compiler/xla/service/gpu/gpu_conv_algorithm_picker.cc:727] None of the algorithms provided by cuDNN heuristics worked; trying fallback algorithms.  Conv: (f32[1,1,512,512]{2,1,3,0}, u8[0]{0}) custom-call(f32[1,1,512,512]{2,1,3,0}, f32[1,1,1,512]{1,0,2,3}), window={size=1x1}, dim_labels=b01f_01io->b01f, feature_group_count=512, custom_call_target=\"__cudnn$convForward\", backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29/156 [====>.........................] - ETA: 34:19 - loss: 0.6917 - doa_out_loss: 0.4991 - sed_out_loss: 1.9261 - doa_out_masked_mae: 104.8324 - doa_out_masked_mae2: 41.8093 - doa_out_masked_mae_original: 109.1367 - sed_out_custom_accuracy: 0.3694"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 00:05:44.771823: W tensorflow/core/kernels/data/cache_dataset_ops.cc:296] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - ETA: 0s - loss: 0.6295 - doa_out_loss: 0.4820 - sed_out_loss: 1.4749 - doa_out_masked_mae: 98.1717 - doa_out_masked_mae2: 39.6792 - doa_out_masked_mae_original: 103.3460 - sed_out_custom_accuracy: 0.4608\n",
      "Epoch 1: val_doa_out_masked_mae improved from inf to 78.78399, saving model to saved_doa_model/class_001.h5\n",
      "156/156 [==============================] - 2541s 4s/step - loss: 0.6295 - doa_out_loss: 0.4820 - sed_out_loss: 1.4749 - doa_out_masked_mae: 98.1717 - doa_out_masked_mae2: 39.6792 - doa_out_masked_mae_original: 103.3460 - sed_out_custom_accuracy: 0.4608 - val_loss: 0.5767 - val_doa_out_loss: 0.4379 - val_sed_out_loss: 1.3877 - val_doa_out_masked_mae: 78.7840 - val_doa_out_masked_mae2: 38.6578 - val_doa_out_masked_mae_original: 87.7645 - val_sed_out_custom_accuracy: 0.5184\n",
      "Epoch 2/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.4832 - doa_out_loss: 0.3813 - sed_out_loss: 1.0188 - doa_out_masked_mae: 70.3787 - doa_out_masked_mae2: 31.2280 - doa_out_masked_mae_original: 76.6619 - sed_out_custom_accuracy: 0.6022\n",
      "Epoch 2: val_doa_out_masked_mae did not improve from 78.78399\n",
      "156/156 [==============================] - 170s 900ms/step - loss: 0.4832 - doa_out_loss: 0.3813 - sed_out_loss: 1.0188 - doa_out_masked_mae: 70.3787 - doa_out_masked_mae2: 31.2280 - doa_out_masked_mae_original: 76.6619 - sed_out_custom_accuracy: 0.6022 - val_loss: 0.5784 - val_doa_out_loss: 0.4800 - val_sed_out_loss: 0.9837 - val_doa_out_masked_mae: 79.8463 - val_doa_out_masked_mae2: 28.7464 - val_doa_out_masked_mae_original: 91.9351 - val_sed_out_custom_accuracy: 0.6802\n",
      "Epoch 3/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.3897 - doa_out_loss: 0.3152 - sed_out_loss: 0.7451 - doa_out_masked_mae: 58.9302 - doa_out_masked_mae2: 26.2730 - doa_out_masked_mae_original: 65.9083 - sed_out_custom_accuracy: 0.7325\n",
      "Epoch 3: val_doa_out_masked_mae improved from 78.78399 to 77.28704, saving model to saved_doa_model/class_003.h5\n",
      "156/156 [==============================] - 195s 894ms/step - loss: 0.3897 - doa_out_loss: 0.3152 - sed_out_loss: 0.7451 - doa_out_masked_mae: 58.9302 - doa_out_masked_mae2: 26.2730 - doa_out_masked_mae_original: 65.9083 - sed_out_custom_accuracy: 0.7325 - val_loss: 0.6323 - val_doa_out_loss: 0.5328 - val_sed_out_loss: 0.9947 - val_doa_out_masked_mae: 77.2870 - val_doa_out_masked_mae2: 27.8119 - val_doa_out_masked_mae_original: 87.5888 - val_sed_out_custom_accuracy: 0.6817\n",
      "Epoch 4/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.3383 - doa_out_loss: 0.2809 - sed_out_loss: 0.5739 - doa_out_masked_mae: 54.1698 - doa_out_masked_mae2: 24.1502 - doa_out_masked_mae_original: 61.3322 - sed_out_custom_accuracy: 0.8019\n",
      "Epoch 4: val_doa_out_masked_mae improved from 77.28704 to 56.85054, saving model to saved_doa_model/class_004.h5\n",
      "156/156 [==============================] - 168s 899ms/step - loss: 0.3383 - doa_out_loss: 0.2809 - sed_out_loss: 0.5739 - doa_out_masked_mae: 54.1698 - doa_out_masked_mae2: 24.1502 - doa_out_masked_mae_original: 61.3322 - sed_out_custom_accuracy: 0.8019 - val_loss: 0.4489 - val_doa_out_loss: 0.3559 - val_sed_out_loss: 0.9300 - val_doa_out_masked_mae: 56.8505 - val_doa_out_masked_mae2: 27.7232 - val_doa_out_masked_mae_original: 63.6713 - val_sed_out_custom_accuracy: 0.7341\n",
      "Epoch 5/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.3027 - doa_out_loss: 0.2568 - sed_out_loss: 0.4590 - doa_out_masked_mae: 50.4027 - doa_out_masked_mae2: 22.6254 - doa_out_masked_mae_original: 57.5012 - sed_out_custom_accuracy: 0.8453\n",
      "Epoch 5: val_doa_out_masked_mae improved from 56.85054 to 42.38284, saving model to saved_doa_model/class_005.h5\n",
      "156/156 [==============================] - 169s 894ms/step - loss: 0.3027 - doa_out_loss: 0.2568 - sed_out_loss: 0.4590 - doa_out_masked_mae: 50.4027 - doa_out_masked_mae2: 22.6254 - doa_out_masked_mae_original: 57.5012 - sed_out_custom_accuracy: 0.8453 - val_loss: 0.3004 - val_doa_out_loss: 0.2255 - val_sed_out_loss: 0.7490 - val_doa_out_masked_mae: 42.3828 - val_doa_out_masked_mae2: 21.3199 - val_doa_out_masked_mae_original: 48.4784 - val_sed_out_custom_accuracy: 0.8042\n",
      "Epoch 6/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.2782 - doa_out_loss: 0.2401 - sed_out_loss: 0.3814 - doa_out_masked_mae: 47.8505 - doa_out_masked_mae2: 21.4342 - doa_out_masked_mae_original: 54.6564 - sed_out_custom_accuracy: 0.8733\n",
      "Epoch 6: val_doa_out_masked_mae did not improve from 42.38284\n",
      "156/156 [==============================] - 169s 899ms/step - loss: 0.2782 - doa_out_loss: 0.2401 - sed_out_loss: 0.3814 - doa_out_masked_mae: 47.8505 - doa_out_masked_mae2: 21.4342 - doa_out_masked_mae_original: 54.6564 - sed_out_custom_accuracy: 0.8733 - val_loss: 0.4227 - val_doa_out_loss: 0.3328 - val_sed_out_loss: 0.8989 - val_doa_out_masked_mae: 57.5802 - val_doa_out_masked_mae2: 21.9885 - val_doa_out_masked_mae_original: 67.1911 - val_sed_out_custom_accuracy: 0.7945\n",
      "Epoch 7/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.2563 - doa_out_loss: 0.2227 - sed_out_loss: 0.3365 - doa_out_masked_mae: 44.9000 - doa_out_masked_mae2: 20.4822 - doa_out_masked_mae_original: 51.5520 - sed_out_custom_accuracy: 0.8884\n",
      "Epoch 7: val_doa_out_masked_mae did not improve from 42.38284\n",
      "156/156 [==============================] - 170s 896ms/step - loss: 0.2563 - doa_out_loss: 0.2227 - sed_out_loss: 0.3365 - doa_out_masked_mae: 44.9000 - doa_out_masked_mae2: 20.4822 - doa_out_masked_mae_original: 51.5520 - sed_out_custom_accuracy: 0.8884 - val_loss: 0.3974 - val_doa_out_loss: 0.3204 - val_sed_out_loss: 0.7701 - val_doa_out_masked_mae: 52.6776 - val_doa_out_masked_mae2: 22.4765 - val_doa_out_masked_mae_original: 60.4378 - val_sed_out_custom_accuracy: 0.7769\n",
      "Epoch 8/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.2343 - doa_out_loss: 0.2048 - sed_out_loss: 0.2953 - doa_out_masked_mae: 41.6400 - doa_out_masked_mae2: 19.3990 - doa_out_masked_mae_original: 47.5837 - sed_out_custom_accuracy: 0.9020\n",
      "Epoch 8: val_doa_out_masked_mae improved from 42.38284 to 33.36450, saving model to saved_doa_model/class_008.h5\n",
      "156/156 [==============================] - 175s 922ms/step - loss: 0.2343 - doa_out_loss: 0.2048 - sed_out_loss: 0.2953 - doa_out_masked_mae: 41.6400 - doa_out_masked_mae2: 19.3990 - doa_out_masked_mae_original: 47.5837 - sed_out_custom_accuracy: 0.9020 - val_loss: 0.2118 - val_doa_out_loss: 0.1734 - val_sed_out_loss: 0.3841 - val_doa_out_masked_mae: 33.3645 - val_doa_out_masked_mae2: 17.3270 - val_doa_out_masked_mae_original: 37.9429 - val_sed_out_custom_accuracy: 0.9000\n",
      "Epoch 9/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.2227 - doa_out_loss: 0.1946 - sed_out_loss: 0.2810 - doa_out_masked_mae: 39.5627 - doa_out_masked_mae2: 18.7134 - doa_out_masked_mae_original: 45.0377 - sed_out_custom_accuracy: 0.9057\n",
      "Epoch 9: val_doa_out_masked_mae did not improve from 33.36450\n",
      "156/156 [==============================] - 168s 891ms/step - loss: 0.2227 - doa_out_loss: 0.1946 - sed_out_loss: 0.2810 - doa_out_masked_mae: 39.5627 - doa_out_masked_mae2: 18.7134 - doa_out_masked_mae_original: 45.0377 - sed_out_custom_accuracy: 0.9057 - val_loss: 0.2436 - val_doa_out_loss: 0.1834 - val_sed_out_loss: 0.6028 - val_doa_out_masked_mae: 34.2066 - val_doa_out_masked_mae2: 18.2493 - val_doa_out_masked_mae_original: 40.1535 - val_sed_out_custom_accuracy: 0.8290\n",
      "Epoch 10/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.2089 - doa_out_loss: 0.1833 - sed_out_loss: 0.2565 - doa_out_masked_mae: 37.2160 - doa_out_masked_mae2: 17.9454 - doa_out_masked_mae_original: 42.3581 - sed_out_custom_accuracy: 0.9143\n",
      "Epoch 10: val_doa_out_masked_mae improved from 33.36450 to 29.95975, saving model to saved_doa_model/class_010.h5\n",
      "156/156 [==============================] - 185s 896ms/step - loss: 0.2089 - doa_out_loss: 0.1833 - sed_out_loss: 0.2565 - doa_out_masked_mae: 37.2160 - doa_out_masked_mae2: 17.9454 - doa_out_masked_mae_original: 42.3581 - sed_out_custom_accuracy: 0.9143 - val_loss: 0.1995 - val_doa_out_loss: 0.1544 - val_sed_out_loss: 0.4510 - val_doa_out_masked_mae: 29.9598 - val_doa_out_masked_mae2: 16.5507 - val_doa_out_masked_mae_original: 33.8060 - val_sed_out_custom_accuracy: 0.8755\n",
      "Epoch 11/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.2003 - doa_out_loss: 0.1758 - sed_out_loss: 0.2451 - doa_out_masked_mae: 35.8443 - doa_out_masked_mae2: 17.5366 - doa_out_masked_mae_original: 40.6528 - sed_out_custom_accuracy: 0.9168\n",
      "Epoch 11: val_doa_out_masked_mae did not improve from 29.95975\n",
      "156/156 [==============================] - 170s 912ms/step - loss: 0.2003 - doa_out_loss: 0.1758 - sed_out_loss: 0.2451 - doa_out_masked_mae: 35.8443 - doa_out_masked_mae2: 17.5366 - doa_out_masked_mae_original: 40.6528 - sed_out_custom_accuracy: 0.9168 - val_loss: 0.2112 - val_doa_out_loss: 0.1759 - val_sed_out_loss: 0.3531 - val_doa_out_masked_mae: 41.5826 - val_doa_out_masked_mae2: 16.9487 - val_doa_out_masked_mae_original: 42.5333 - val_sed_out_custom_accuracy: 0.9061\n",
      "Epoch 12/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1898 - doa_out_loss: 0.1667 - sed_out_loss: 0.2302 - doa_out_masked_mae: 34.1014 - doa_out_masked_mae2: 16.9852 - doa_out_masked_mae_original: 38.5885 - sed_out_custom_accuracy: 0.9220\n",
      "Epoch 12: val_doa_out_masked_mae did not improve from 29.95975\n",
      "156/156 [==============================] - 171s 900ms/step - loss: 0.1898 - doa_out_loss: 0.1667 - sed_out_loss: 0.2302 - doa_out_masked_mae: 34.1014 - doa_out_masked_mae2: 16.9852 - doa_out_masked_mae_original: 38.5885 - sed_out_custom_accuracy: 0.9220 - val_loss: 0.1866 - val_doa_out_loss: 0.1510 - val_sed_out_loss: 0.3557 - val_doa_out_masked_mae: 30.2614 - val_doa_out_masked_mae2: 17.3097 - val_doa_out_masked_mae_original: 32.6026 - val_sed_out_custom_accuracy: 0.9095\n",
      "Epoch 13/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1839 - doa_out_loss: 0.1621 - sed_out_loss: 0.2179 - doa_out_masked_mae: 33.6334 - doa_out_masked_mae2: 16.7606 - doa_out_masked_mae_original: 37.9169 - sed_out_custom_accuracy: 0.9258\n",
      "Epoch 13: val_doa_out_masked_mae did not improve from 29.95975\n",
      "156/156 [==============================] - 171s 921ms/step - loss: 0.1839 - doa_out_loss: 0.1621 - sed_out_loss: 0.2179 - doa_out_masked_mae: 33.6334 - doa_out_masked_mae2: 16.7606 - doa_out_masked_mae_original: 37.9169 - sed_out_custom_accuracy: 0.9258 - val_loss: 0.2201 - val_doa_out_loss: 0.1725 - val_sed_out_loss: 0.4760 - val_doa_out_masked_mae: 32.3905 - val_doa_out_masked_mae2: 19.1551 - val_doa_out_masked_mae_original: 36.4366 - val_sed_out_custom_accuracy: 0.8700\n",
      "Epoch 14/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1781 - doa_out_loss: 0.1571 - sed_out_loss: 0.2100 - doa_out_masked_mae: 32.7355 - doa_out_masked_mae2: 16.3991 - doa_out_masked_mae_original: 36.8416 - sed_out_custom_accuracy: 0.9291\n",
      "Epoch 14: val_doa_out_masked_mae did not improve from 29.95975\n",
      "156/156 [==============================] - 165s 894ms/step - loss: 0.1781 - doa_out_loss: 0.1571 - sed_out_loss: 0.2100 - doa_out_masked_mae: 32.7355 - doa_out_masked_mae2: 16.3991 - doa_out_masked_mae_original: 36.8416 - sed_out_custom_accuracy: 0.9291 - val_loss: 0.3221 - val_doa_out_loss: 0.2134 - val_sed_out_loss: 1.0868 - val_doa_out_masked_mae: 43.4909 - val_doa_out_masked_mae2: 18.5969 - val_doa_out_masked_mae_original: 47.3100 - val_sed_out_custom_accuracy: 0.6900\n",
      "Epoch 15/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1725 - doa_out_loss: 0.1518 - sed_out_loss: 0.2075 - doa_out_masked_mae: 31.6553 - doa_out_masked_mae2: 15.9262 - doa_out_masked_mae_original: 35.7481 - sed_out_custom_accuracy: 0.9289\n",
      "Epoch 15: val_doa_out_masked_mae did not improve from 29.95975\n",
      "156/156 [==============================] - 178s 920ms/step - loss: 0.1725 - doa_out_loss: 0.1518 - sed_out_loss: 0.2075 - doa_out_masked_mae: 31.6553 - doa_out_masked_mae2: 15.9262 - doa_out_masked_mae_original: 35.7481 - sed_out_custom_accuracy: 0.9289 - val_loss: 0.2365 - val_doa_out_loss: 0.2037 - val_sed_out_loss: 0.3273 - val_doa_out_masked_mae: 47.1605 - val_doa_out_masked_mae2: 17.8348 - val_doa_out_masked_mae_original: 47.7561 - val_sed_out_custom_accuracy: 0.8978\n",
      "Epoch 16/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1652 - doa_out_loss: 0.1454 - sed_out_loss: 0.1977 - doa_out_masked_mae: 30.6644 - doa_out_masked_mae2: 15.4669 - doa_out_masked_mae_original: 34.4636 - sed_out_custom_accuracy: 0.9330\n",
      "Epoch 16: val_doa_out_masked_mae improved from 29.95975 to 29.31929, saving model to saved_doa_model/class_016.h5\n",
      "156/156 [==============================] - 168s 913ms/step - loss: 0.1652 - doa_out_loss: 0.1454 - sed_out_loss: 0.1977 - doa_out_masked_mae: 30.6644 - doa_out_masked_mae2: 15.4669 - doa_out_masked_mae_original: 34.4636 - sed_out_custom_accuracy: 0.9330 - val_loss: 0.1924 - val_doa_out_loss: 0.1613 - val_sed_out_loss: 0.3119 - val_doa_out_masked_mae: 29.3193 - val_doa_out_masked_mae2: 17.1547 - val_doa_out_masked_mae_original: 32.7132 - val_sed_out_custom_accuracy: 0.9121\n",
      "Epoch 17/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1626 - doa_out_loss: 0.1429 - sed_out_loss: 0.1974 - doa_out_masked_mae: 30.3710 - doa_out_masked_mae2: 15.1926 - doa_out_masked_mae_original: 34.1618 - sed_out_custom_accuracy: 0.9317\n",
      "Epoch 17: val_doa_out_masked_mae improved from 29.31929 to 25.14696, saving model to saved_doa_model/class_017.h5\n",
      "156/156 [==============================] - 186s 893ms/step - loss: 0.1626 - doa_out_loss: 0.1429 - sed_out_loss: 0.1974 - doa_out_masked_mae: 30.3710 - doa_out_masked_mae2: 15.1926 - doa_out_masked_mae_original: 34.1618 - sed_out_custom_accuracy: 0.9317 - val_loss: 0.1453 - val_doa_out_loss: 0.1198 - val_sed_out_loss: 0.2550 - val_doa_out_masked_mae: 25.1470 - val_doa_out_masked_mae2: 13.8173 - val_doa_out_masked_mae_original: 27.4515 - val_sed_out_custom_accuracy: 0.9385\n",
      "Epoch 18/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1575 - doa_out_loss: 0.1388 - sed_out_loss: 0.1872 - doa_out_masked_mae: 29.8700 - doa_out_masked_mae2: 15.0544 - doa_out_masked_mae_original: 33.6536 - sed_out_custom_accuracy: 0.9360\n",
      "Epoch 18: val_doa_out_masked_mae did not improve from 25.14696\n",
      "156/156 [==============================] - 164s 890ms/step - loss: 0.1575 - doa_out_loss: 0.1388 - sed_out_loss: 0.1872 - doa_out_masked_mae: 29.8700 - doa_out_masked_mae2: 15.0544 - doa_out_masked_mae_original: 33.6536 - sed_out_custom_accuracy: 0.9360 - val_loss: 0.1616 - val_doa_out_loss: 0.1344 - val_sed_out_loss: 0.2724 - val_doa_out_masked_mae: 28.2417 - val_doa_out_masked_mae2: 14.3714 - val_doa_out_masked_mae_original: 31.9199 - val_sed_out_custom_accuracy: 0.9300\n",
      "Epoch 19/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1539 - doa_out_loss: 0.1355 - sed_out_loss: 0.1846 - doa_out_masked_mae: 29.1685 - doa_out_masked_mae2: 14.6429 - doa_out_masked_mae_original: 32.8241 - sed_out_custom_accuracy: 0.9362\n",
      "Epoch 19: val_doa_out_masked_mae did not improve from 25.14696\n",
      "156/156 [==============================] - 167s 903ms/step - loss: 0.1539 - doa_out_loss: 0.1355 - sed_out_loss: 0.1846 - doa_out_masked_mae: 29.1685 - doa_out_masked_mae2: 14.6429 - doa_out_masked_mae_original: 32.8241 - sed_out_custom_accuracy: 0.9362 - val_loss: 0.2197 - val_doa_out_loss: 0.1750 - val_sed_out_loss: 0.4471 - val_doa_out_masked_mae: 30.8863 - val_doa_out_masked_mae2: 17.9639 - val_doa_out_masked_mae_original: 35.5899 - val_sed_out_custom_accuracy: 0.8848\n",
      "Epoch 20/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1494 - doa_out_loss: 0.1315 - sed_out_loss: 0.1796 - doa_out_masked_mae: 28.5554 - doa_out_masked_mae2: 14.4814 - doa_out_masked_mae_original: 32.0068 - sed_out_custom_accuracy: 0.9386\n",
      "Epoch 20: val_doa_out_masked_mae improved from 25.14696 to 24.94165, saving model to saved_doa_model/class_020.h5\n",
      "156/156 [==============================] - 167s 893ms/step - loss: 0.1494 - doa_out_loss: 0.1315 - sed_out_loss: 0.1796 - doa_out_masked_mae: 28.5554 - doa_out_masked_mae2: 14.4814 - doa_out_masked_mae_original: 32.0068 - sed_out_custom_accuracy: 0.9386 - val_loss: 0.1518 - val_doa_out_loss: 0.1277 - val_sed_out_loss: 0.2415 - val_doa_out_masked_mae: 24.9416 - val_doa_out_masked_mae2: 15.0892 - val_doa_out_masked_mae_original: 27.2934 - val_sed_out_custom_accuracy: 0.9285\n",
      "Epoch 21/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1455 - doa_out_loss: 0.1280 - sed_out_loss: 0.1754 - doa_out_masked_mae: 28.1228 - doa_out_masked_mae2: 14.1911 - doa_out_masked_mae_original: 31.5220 - sed_out_custom_accuracy: 0.9390\n",
      "Epoch 21: val_doa_out_masked_mae did not improve from 24.94165\n",
      "156/156 [==============================] - 170s 915ms/step - loss: 0.1455 - doa_out_loss: 0.1280 - sed_out_loss: 0.1754 - doa_out_masked_mae: 28.1228 - doa_out_masked_mae2: 14.1911 - doa_out_masked_mae_original: 31.5220 - sed_out_custom_accuracy: 0.9390 - val_loss: 0.2974 - val_doa_out_loss: 0.2441 - val_sed_out_loss: 0.5334 - val_doa_out_masked_mae: 55.1974 - val_doa_out_masked_mae2: 18.3990 - val_doa_out_masked_mae_original: 55.2845 - val_sed_out_custom_accuracy: 0.8547\n",
      "Epoch 22/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1417 - doa_out_loss: 0.1244 - sed_out_loss: 0.1732 - doa_out_masked_mae: 27.4871 - doa_out_masked_mae2: 13.9063 - doa_out_masked_mae_original: 30.7808 - sed_out_custom_accuracy: 0.9404\n",
      "Epoch 22: val_doa_out_masked_mae did not improve from 24.94165\n",
      "156/156 [==============================] - 186s 897ms/step - loss: 0.1417 - doa_out_loss: 0.1244 - sed_out_loss: 0.1732 - doa_out_masked_mae: 27.4871 - doa_out_masked_mae2: 13.9063 - doa_out_masked_mae_original: 30.7808 - sed_out_custom_accuracy: 0.9404 - val_loss: 0.1477 - val_doa_out_loss: 0.1234 - val_sed_out_loss: 0.2435 - val_doa_out_masked_mae: 25.6047 - val_doa_out_masked_mae2: 13.6370 - val_doa_out_masked_mae_original: 30.3636 - val_sed_out_custom_accuracy: 0.9295\n",
      "Epoch 23/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1391 - doa_out_loss: 0.1225 - sed_out_loss: 0.1655 - doa_out_masked_mae: 27.1482 - doa_out_masked_mae2: 13.7018 - doa_out_masked_mae_original: 30.3225 - sed_out_custom_accuracy: 0.9426\n",
      "Epoch 23: val_doa_out_masked_mae did not improve from 24.94165\n",
      "156/156 [==============================] - 165s 899ms/step - loss: 0.1391 - doa_out_loss: 0.1225 - sed_out_loss: 0.1655 - doa_out_masked_mae: 27.1482 - doa_out_masked_mae2: 13.7018 - doa_out_masked_mae_original: 30.3225 - sed_out_custom_accuracy: 0.9426 - val_loss: 0.1910 - val_doa_out_loss: 0.1291 - val_sed_out_loss: 0.6193 - val_doa_out_masked_mae: 30.5177 - val_doa_out_masked_mae2: 13.9096 - val_doa_out_masked_mae_original: 33.0626 - val_sed_out_custom_accuracy: 0.7882\n",
      "Epoch 24/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1344 - doa_out_loss: 0.1182 - sed_out_loss: 0.1617 - doa_out_masked_mae: 26.5850 - doa_out_masked_mae2: 13.3590 - doa_out_masked_mae_original: 29.7393 - sed_out_custom_accuracy: 0.9438\n",
      "Epoch 24: val_doa_out_masked_mae did not improve from 24.94165\n",
      "156/156 [==============================] - 171s 898ms/step - loss: 0.1344 - doa_out_loss: 0.1182 - sed_out_loss: 0.1617 - doa_out_masked_mae: 26.5850 - doa_out_masked_mae2: 13.3590 - doa_out_masked_mae_original: 29.7393 - sed_out_custom_accuracy: 0.9438 - val_loss: 0.1341 - val_doa_out_loss: 0.1141 - val_sed_out_loss: 0.1995 - val_doa_out_masked_mae: 26.3154 - val_doa_out_masked_mae2: 13.0423 - val_doa_out_masked_mae_original: 28.1060 - val_sed_out_custom_accuracy: 0.9376\n",
      "Epoch 25/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1323 - doa_out_loss: 0.1164 - sed_out_loss: 0.1591 - doa_out_masked_mae: 26.2935 - doa_out_masked_mae2: 13.3701 - doa_out_masked_mae_original: 29.4444 - sed_out_custom_accuracy: 0.9457\n",
      "Epoch 25: val_doa_out_masked_mae improved from 24.94165 to 22.40433, saving model to saved_doa_model/class_025.h5\n",
      "156/156 [==============================] - 168s 905ms/step - loss: 0.1323 - doa_out_loss: 0.1164 - sed_out_loss: 0.1591 - doa_out_masked_mae: 26.2935 - doa_out_masked_mae2: 13.3701 - doa_out_masked_mae_original: 29.4444 - sed_out_custom_accuracy: 0.9457 - val_loss: 0.1278 - val_doa_out_loss: 0.0987 - val_sed_out_loss: 0.2908 - val_doa_out_masked_mae: 22.4043 - val_doa_out_masked_mae2: 11.3288 - val_doa_out_masked_mae_original: 24.4063 - val_sed_out_custom_accuracy: 0.8931\n",
      "Epoch 26/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1287 - doa_out_loss: 0.1130 - sed_out_loss: 0.1567 - doa_out_masked_mae: 25.7847 - doa_out_masked_mae2: 12.9455 - doa_out_masked_mae_original: 28.8417 - sed_out_custom_accuracy: 0.9462\n",
      "Epoch 26: val_doa_out_masked_mae did not improve from 22.40433\n",
      "156/156 [==============================] - 164s 877ms/step - loss: 0.1287 - doa_out_loss: 0.1130 - sed_out_loss: 0.1567 - doa_out_masked_mae: 25.7847 - doa_out_masked_mae2: 12.9455 - doa_out_masked_mae_original: 28.8417 - sed_out_custom_accuracy: 0.9462 - val_loss: 0.1836 - val_doa_out_loss: 0.1519 - val_sed_out_loss: 0.3176 - val_doa_out_masked_mae: 31.9534 - val_doa_out_masked_mae2: 14.7483 - val_doa_out_masked_mae_original: 34.8650 - val_sed_out_custom_accuracy: 0.9039\n",
      "Epoch 27/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1271 - doa_out_loss: 0.1116 - sed_out_loss: 0.1555 - doa_out_masked_mae: 25.5980 - doa_out_masked_mae2: 12.9200 - doa_out_masked_mae_original: 28.5715 - sed_out_custom_accuracy: 0.9450\n",
      "Epoch 27: val_doa_out_masked_mae did not improve from 22.40433\n",
      "156/156 [==============================] - 168s 905ms/step - loss: 0.1271 - doa_out_loss: 0.1116 - sed_out_loss: 0.1555 - doa_out_masked_mae: 25.5980 - doa_out_masked_mae2: 12.9200 - doa_out_masked_mae_original: 28.5715 - sed_out_custom_accuracy: 0.9450 - val_loss: 0.1725 - val_doa_out_loss: 0.1472 - val_sed_out_loss: 0.2535 - val_doa_out_masked_mae: 28.6416 - val_doa_out_masked_mae2: 17.4245 - val_doa_out_masked_mae_original: 30.7871 - val_sed_out_custom_accuracy: 0.9157\n",
      "Epoch 28/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1250 - doa_out_loss: 0.1100 - sed_out_loss: 0.1499 - doa_out_masked_mae: 25.3589 - doa_out_masked_mae2: 12.7690 - doa_out_masked_mae_original: 28.2607 - sed_out_custom_accuracy: 0.9484\n",
      "Epoch 28: val_doa_out_masked_mae did not improve from 22.40433\n",
      "156/156 [==============================] - 172s 920ms/step - loss: 0.1250 - doa_out_loss: 0.1100 - sed_out_loss: 0.1499 - doa_out_masked_mae: 25.3589 - doa_out_masked_mae2: 12.7690 - doa_out_masked_mae_original: 28.2607 - sed_out_custom_accuracy: 0.9484 - val_loss: 0.1342 - val_doa_out_loss: 0.1161 - val_sed_out_loss: 0.1807 - val_doa_out_masked_mae: 23.4816 - val_doa_out_masked_mae2: 13.0062 - val_doa_out_masked_mae_original: 27.1966 - val_sed_out_custom_accuracy: 0.9450\n",
      "Epoch 29/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1219 - doa_out_loss: 0.1073 - sed_out_loss: 0.1467 - doa_out_masked_mae: 24.7241 - doa_out_masked_mae2: 12.5586 - doa_out_masked_mae_original: 27.5913 - sed_out_custom_accuracy: 0.9491\n",
      "Epoch 29: val_doa_out_masked_mae did not improve from 22.40433\n",
      "156/156 [==============================] - 180s 896ms/step - loss: 0.1219 - doa_out_loss: 0.1073 - sed_out_loss: 0.1467 - doa_out_masked_mae: 24.7241 - doa_out_masked_mae2: 12.5586 - doa_out_masked_mae_original: 27.5913 - sed_out_custom_accuracy: 0.9491 - val_loss: 0.1289 - val_doa_out_loss: 0.1094 - val_sed_out_loss: 0.1946 - val_doa_out_masked_mae: 22.9622 - val_doa_out_masked_mae2: 12.7775 - val_doa_out_masked_mae_original: 26.2561 - val_sed_out_custom_accuracy: 0.9454\n",
      "Epoch 30/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1206 - doa_out_loss: 0.1061 - sed_out_loss: 0.1455 - doa_out_masked_mae: 24.6498 - doa_out_masked_mae2: 12.4400 - doa_out_masked_mae_original: 27.4831 - sed_out_custom_accuracy: 0.9498\n",
      "Epoch 30: val_doa_out_masked_mae did not improve from 22.40433\n",
      "156/156 [==============================] - 167s 893ms/step - loss: 0.1206 - doa_out_loss: 0.1061 - sed_out_loss: 0.1455 - doa_out_masked_mae: 24.6498 - doa_out_masked_mae2: 12.4400 - doa_out_masked_mae_original: 27.4831 - sed_out_custom_accuracy: 0.9498 - val_loss: 0.1289 - val_doa_out_loss: 0.0970 - val_sed_out_loss: 0.3189 - val_doa_out_masked_mae: 24.0067 - val_doa_out_masked_mae2: 11.5853 - val_doa_out_masked_mae_original: 25.5742 - val_sed_out_custom_accuracy: 0.9002\n",
      "Epoch 31/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1184 - doa_out_loss: 0.1034 - sed_out_loss: 0.1508 - doa_out_masked_mae: 23.9236 - doa_out_masked_mae2: 12.2149 - doa_out_masked_mae_original: 26.7584 - sed_out_custom_accuracy: 0.9470\n",
      "Epoch 31: val_doa_out_masked_mae did not improve from 22.40433\n",
      "156/156 [==============================] - 171s 900ms/step - loss: 0.1184 - doa_out_loss: 0.1034 - sed_out_loss: 0.1508 - doa_out_masked_mae: 23.9236 - doa_out_masked_mae2: 12.2149 - doa_out_masked_mae_original: 26.7584 - sed_out_custom_accuracy: 0.9470 - val_loss: 0.1345 - val_doa_out_loss: 0.1045 - val_sed_out_loss: 0.2992 - val_doa_out_masked_mae: 26.3704 - val_doa_out_masked_mae2: 11.7868 - val_doa_out_masked_mae_original: 28.3677 - val_sed_out_custom_accuracy: 0.9185\n",
      "Epoch 32/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1163 - doa_out_loss: 0.1024 - sed_out_loss: 0.1388 - doa_out_masked_mae: 23.9247 - doa_out_masked_mae2: 12.0673 - doa_out_masked_mae_original: 26.7062 - sed_out_custom_accuracy: 0.9518\n",
      "Epoch 32: val_doa_out_masked_mae did not improve from 22.40433\n",
      "156/156 [==============================] - 185s 911ms/step - loss: 0.1163 - doa_out_loss: 0.1024 - sed_out_loss: 0.1388 - doa_out_masked_mae: 23.9247 - doa_out_masked_mae2: 12.0673 - doa_out_masked_mae_original: 26.7062 - sed_out_custom_accuracy: 0.9518 - val_loss: 0.1766 - val_doa_out_loss: 0.1575 - val_sed_out_loss: 0.1910 - val_doa_out_masked_mae: 28.5172 - val_doa_out_masked_mae2: 17.6929 - val_doa_out_masked_mae_original: 31.0177 - val_sed_out_custom_accuracy: 0.9465\n",
      "Epoch 33/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1156 - doa_out_loss: 0.1020 - sed_out_loss: 0.1363 - doa_out_masked_mae: 23.7895 - doa_out_masked_mae2: 12.1517 - doa_out_masked_mae_original: 26.5488 - sed_out_custom_accuracy: 0.9532\n",
      "Epoch 33: val_doa_out_masked_mae improved from 22.40433 to 21.79504, saving model to saved_doa_model/class_033.h5\n",
      "156/156 [==============================] - 168s 909ms/step - loss: 0.1156 - doa_out_loss: 0.1020 - sed_out_loss: 0.1363 - doa_out_masked_mae: 23.7895 - doa_out_masked_mae2: 12.1517 - doa_out_masked_mae_original: 26.5488 - sed_out_custom_accuracy: 0.9532 - val_loss: 0.1231 - val_doa_out_loss: 0.1017 - val_sed_out_loss: 0.2140 - val_doa_out_masked_mae: 21.7950 - val_doa_out_masked_mae2: 11.8082 - val_doa_out_masked_mae_original: 24.2145 - val_sed_out_custom_accuracy: 0.9237\n",
      "Epoch 34/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1113 - doa_out_loss: 0.0979 - sed_out_loss: 0.1340 - doa_out_masked_mae: 23.3897 - doa_out_masked_mae2: 11.7226 - doa_out_masked_mae_original: 26.0184 - sed_out_custom_accuracy: 0.9540\n",
      "Epoch 34: val_doa_out_masked_mae did not improve from 21.79504\n",
      "156/156 [==============================] - 164s 883ms/step - loss: 0.1113 - doa_out_loss: 0.0979 - sed_out_loss: 0.1340 - doa_out_masked_mae: 23.3897 - doa_out_masked_mae2: 11.7226 - doa_out_masked_mae_original: 26.0184 - sed_out_custom_accuracy: 0.9540 - val_loss: 0.1300 - val_doa_out_loss: 0.1038 - val_sed_out_loss: 0.2624 - val_doa_out_masked_mae: 23.7894 - val_doa_out_masked_mae2: 12.0726 - val_doa_out_masked_mae_original: 25.2758 - val_sed_out_custom_accuracy: 0.9176\n",
      "Epoch 35/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1111 - doa_out_loss: 0.0979 - sed_out_loss: 0.1323 - doa_out_masked_mae: 23.1593 - doa_out_masked_mae2: 11.7985 - doa_out_masked_mae_original: 25.8957 - sed_out_custom_accuracy: 0.9539\n",
      "Epoch 35: val_doa_out_masked_mae did not improve from 21.79504\n",
      "156/156 [==============================] - 168s 906ms/step - loss: 0.1111 - doa_out_loss: 0.0979 - sed_out_loss: 0.1323 - doa_out_masked_mae: 23.1593 - doa_out_masked_mae2: 11.7985 - doa_out_masked_mae_original: 25.8957 - sed_out_custom_accuracy: 0.9539 - val_loss: 0.1274 - val_doa_out_loss: 0.1042 - val_sed_out_loss: 0.2317 - val_doa_out_masked_mae: 27.7279 - val_doa_out_masked_mae2: 12.2046 - val_doa_out_masked_mae_original: 28.8802 - val_sed_out_custom_accuracy: 0.9292\n",
      "Epoch 36/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1084 - doa_out_loss: 0.0955 - sed_out_loss: 0.1288 - doa_out_masked_mae: 22.7869 - doa_out_masked_mae2: 11.6038 - doa_out_masked_mae_original: 25.4969 - sed_out_custom_accuracy: 0.9550\n",
      "Epoch 36: val_doa_out_masked_mae did not improve from 21.79504\n",
      "156/156 [==============================] - 169s 905ms/step - loss: 0.1084 - doa_out_loss: 0.0955 - sed_out_loss: 0.1288 - doa_out_masked_mae: 22.7869 - doa_out_masked_mae2: 11.6038 - doa_out_masked_mae_original: 25.4969 - sed_out_custom_accuracy: 0.9550 - val_loss: 0.1199 - val_doa_out_loss: 0.0992 - val_sed_out_loss: 0.2067 - val_doa_out_masked_mae: 27.0876 - val_doa_out_masked_mae2: 11.3533 - val_doa_out_masked_mae_original: 28.5035 - val_sed_out_custom_accuracy: 0.9270\n",
      "Epoch 37/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1072 - doa_out_loss: 0.0944 - sed_out_loss: 0.1278 - doa_out_masked_mae: 22.5574 - doa_out_masked_mae2: 11.5001 - doa_out_masked_mae_original: 25.1600 - sed_out_custom_accuracy: 0.9557\n",
      "Epoch 37: val_doa_out_masked_mae did not improve from 21.79504\n",
      "156/156 [==============================] - 192s 929ms/step - loss: 0.1072 - doa_out_loss: 0.0944 - sed_out_loss: 0.1278 - doa_out_masked_mae: 22.5574 - doa_out_masked_mae2: 11.5001 - doa_out_masked_mae_original: 25.1600 - sed_out_custom_accuracy: 0.9557 - val_loss: 0.1525 - val_doa_out_loss: 0.1327 - val_sed_out_loss: 0.1979 - val_doa_out_masked_mae: 28.6489 - val_doa_out_masked_mae2: 15.5124 - val_doa_out_masked_mae_original: 30.3397 - val_sed_out_custom_accuracy: 0.9332\n",
      "Epoch 38/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1065 - doa_out_loss: 0.0941 - sed_out_loss: 0.1232 - doa_out_masked_mae: 22.4834 - doa_out_masked_mae2: 11.5065 - doa_out_masked_mae_original: 25.0764 - sed_out_custom_accuracy: 0.9569\n",
      "Epoch 38: val_doa_out_masked_mae did not improve from 21.79504\n",
      "156/156 [==============================] - 171s 919ms/step - loss: 0.1065 - doa_out_loss: 0.0941 - sed_out_loss: 0.1232 - doa_out_masked_mae: 22.4834 - doa_out_masked_mae2: 11.5065 - doa_out_masked_mae_original: 25.0764 - sed_out_custom_accuracy: 0.9569 - val_loss: 0.1173 - val_doa_out_loss: 0.0944 - val_sed_out_loss: 0.2283 - val_doa_out_masked_mae: 23.1223 - val_doa_out_masked_mae2: 10.8798 - val_doa_out_masked_mae_original: 24.0357 - val_sed_out_custom_accuracy: 0.9167\n",
      "Epoch 39/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1035 - doa_out_loss: 0.0910 - sed_out_loss: 0.1254 - doa_out_masked_mae: 21.9852 - doa_out_masked_mae2: 11.1603 - doa_out_masked_mae_original: 24.5547 - sed_out_custom_accuracy: 0.9562\n",
      "Epoch 39: val_doa_out_masked_mae did not improve from 21.79504\n",
      "156/156 [==============================] - 178s 894ms/step - loss: 0.1035 - doa_out_loss: 0.0910 - sed_out_loss: 0.1254 - doa_out_masked_mae: 21.9852 - doa_out_masked_mae2: 11.1603 - doa_out_masked_mae_original: 24.5547 - sed_out_custom_accuracy: 0.9562 - val_loss: 0.1680 - val_doa_out_loss: 0.1482 - val_sed_out_loss: 0.1981 - val_doa_out_masked_mae: 29.7401 - val_doa_out_masked_mae2: 14.0222 - val_doa_out_masked_mae_original: 32.7882 - val_sed_out_custom_accuracy: 0.9398\n",
      "Epoch 40/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1027 - doa_out_loss: 0.0905 - sed_out_loss: 0.1217 - doa_out_masked_mae: 21.8401 - doa_out_masked_mae2: 11.1072 - doa_out_masked_mae_original: 24.4245 - sed_out_custom_accuracy: 0.9572\n",
      "Epoch 40: val_doa_out_masked_mae did not improve from 21.79504\n",
      "156/156 [==============================] - 169s 908ms/step - loss: 0.1027 - doa_out_loss: 0.0905 - sed_out_loss: 0.1217 - doa_out_masked_mae: 21.8401 - doa_out_masked_mae2: 11.1072 - doa_out_masked_mae_original: 24.4245 - sed_out_custom_accuracy: 0.9572 - val_loss: 0.1197 - val_doa_out_loss: 0.0977 - val_sed_out_loss: 0.2205 - val_doa_out_masked_mae: 23.4506 - val_doa_out_masked_mae2: 11.4259 - val_doa_out_masked_mae_original: 25.1227 - val_sed_out_custom_accuracy: 0.9325\n",
      "Epoch 41/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1018 - doa_out_loss: 0.0898 - sed_out_loss: 0.1197 - doa_out_masked_mae: 21.7841 - doa_out_masked_mae2: 11.0885 - doa_out_masked_mae_original: 24.2668 - sed_out_custom_accuracy: 0.9574\n",
      "Epoch 41: val_doa_out_masked_mae did not improve from 21.79504\n",
      "156/156 [==============================] - 165s 895ms/step - loss: 0.1018 - doa_out_loss: 0.0898 - sed_out_loss: 0.1197 - doa_out_masked_mae: 21.7841 - doa_out_masked_mae2: 11.0885 - doa_out_masked_mae_original: 24.2668 - sed_out_custom_accuracy: 0.9574 - val_loss: 0.1229 - val_doa_out_loss: 0.1073 - val_sed_out_loss: 0.1563 - val_doa_out_masked_mae: 22.4460 - val_doa_out_masked_mae2: 12.5537 - val_doa_out_masked_mae_original: 24.4309 - val_sed_out_custom_accuracy: 0.9574\n",
      "Epoch 42/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0996 - doa_out_loss: 0.0882 - sed_out_loss: 0.1139 - doa_out_masked_mae: 21.5722 - doa_out_masked_mae2: 10.8942 - doa_out_masked_mae_original: 24.1014 - sed_out_custom_accuracy: 0.9602\n",
      "Epoch 42: val_doa_out_masked_mae did not improve from 21.79504\n",
      "156/156 [==============================] - 180s 935ms/step - loss: 0.0996 - doa_out_loss: 0.0882 - sed_out_loss: 0.1139 - doa_out_masked_mae: 21.5722 - doa_out_masked_mae2: 10.8942 - doa_out_masked_mae_original: 24.1014 - sed_out_custom_accuracy: 0.9602 - val_loss: 0.1186 - val_doa_out_loss: 0.0948 - val_sed_out_loss: 0.2375 - val_doa_out_masked_mae: 25.2875 - val_doa_out_masked_mae2: 10.9672 - val_doa_out_masked_mae_original: 26.2997 - val_sed_out_custom_accuracy: 0.9186\n",
      "Epoch 43/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0988 - doa_out_loss: 0.0871 - sed_out_loss: 0.1165 - doa_out_masked_mae: 21.2843 - doa_out_masked_mae2: 10.8610 - doa_out_masked_mae_original: 23.7684 - sed_out_custom_accuracy: 0.9592\n",
      "Epoch 43: val_doa_out_masked_mae improved from 21.79504 to 19.17259, saving model to saved_doa_model/class_043.h5\n",
      "156/156 [==============================] - 168s 903ms/step - loss: 0.0988 - doa_out_loss: 0.0871 - sed_out_loss: 0.1165 - doa_out_masked_mae: 21.2843 - doa_out_masked_mae2: 10.8610 - doa_out_masked_mae_original: 23.7684 - sed_out_custom_accuracy: 0.9592 - val_loss: 0.1219 - val_doa_out_loss: 0.0943 - val_sed_out_loss: 0.2765 - val_doa_out_masked_mae: 19.1726 - val_doa_out_masked_mae2: 10.6651 - val_doa_out_masked_mae_original: 21.5383 - val_sed_out_custom_accuracy: 0.9338\n",
      "Epoch 44/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0976 - doa_out_loss: 0.0866 - sed_out_loss: 0.1101 - doa_out_masked_mae: 21.3161 - doa_out_masked_mae2: 10.7683 - doa_out_masked_mae_original: 23.7677 - sed_out_custom_accuracy: 0.9619\n",
      "Epoch 44: val_doa_out_masked_mae did not improve from 19.17259\n",
      "156/156 [==============================] - 174s 886ms/step - loss: 0.0976 - doa_out_loss: 0.0866 - sed_out_loss: 0.1101 - doa_out_masked_mae: 21.3161 - doa_out_masked_mae2: 10.7683 - doa_out_masked_mae_original: 23.7677 - sed_out_custom_accuracy: 0.9619 - val_loss: 0.1311 - val_doa_out_loss: 0.1112 - val_sed_out_loss: 0.1985 - val_doa_out_masked_mae: 21.8296 - val_doa_out_masked_mae2: 12.4136 - val_doa_out_masked_mae_original: 24.5813 - val_sed_out_custom_accuracy: 0.9362\n",
      "Epoch 45/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0969 - doa_out_loss: 0.0860 - sed_out_loss: 0.1097 - doa_out_masked_mae: 20.9155 - doa_out_masked_mae2: 10.7539 - doa_out_masked_mae_original: 23.2325 - sed_out_custom_accuracy: 0.9615\n",
      "Epoch 45: val_doa_out_masked_mae did not improve from 19.17259\n",
      "156/156 [==============================] - 166s 901ms/step - loss: 0.0969 - doa_out_loss: 0.0860 - sed_out_loss: 0.1097 - doa_out_masked_mae: 20.9155 - doa_out_masked_mae2: 10.7539 - doa_out_masked_mae_original: 23.2325 - sed_out_custom_accuracy: 0.9615 - val_loss: 0.1360 - val_doa_out_loss: 0.1186 - val_sed_out_loss: 0.1741 - val_doa_out_masked_mae: 24.0443 - val_doa_out_masked_mae2: 12.4478 - val_doa_out_masked_mae_original: 26.7856 - val_sed_out_custom_accuracy: 0.9474\n",
      "Epoch 46/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0954 - doa_out_loss: 0.0842 - sed_out_loss: 0.1111 - doa_out_masked_mae: 20.6810 - doa_out_masked_mae2: 10.6488 - doa_out_masked_mae_original: 22.9490 - sed_out_custom_accuracy: 0.9607\n",
      "Epoch 46: val_doa_out_masked_mae did not improve from 19.17259\n",
      "156/156 [==============================] - 168s 911ms/step - loss: 0.0954 - doa_out_loss: 0.0842 - sed_out_loss: 0.1111 - doa_out_masked_mae: 20.6810 - doa_out_masked_mae2: 10.6488 - doa_out_masked_mae_original: 22.9490 - sed_out_custom_accuracy: 0.9607 - val_loss: 0.1204 - val_doa_out_loss: 0.0972 - val_sed_out_loss: 0.2316 - val_doa_out_masked_mae: 22.1766 - val_doa_out_masked_mae2: 10.4617 - val_doa_out_masked_mae_original: 23.3983 - val_sed_out_custom_accuracy: 0.9224\n",
      "Epoch 47/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0957 - doa_out_loss: 0.0845 - sed_out_loss: 0.1122 - doa_out_masked_mae: 20.8852 - doa_out_masked_mae2: 10.6291 - doa_out_masked_mae_original: 23.2148 - sed_out_custom_accuracy: 0.9611\n",
      "Epoch 47: val_doa_out_masked_mae did not improve from 19.17259\n",
      "156/156 [==============================] - 164s 896ms/step - loss: 0.0957 - doa_out_loss: 0.0845 - sed_out_loss: 0.1122 - doa_out_masked_mae: 20.8852 - doa_out_masked_mae2: 10.6291 - doa_out_masked_mae_original: 23.2148 - sed_out_custom_accuracy: 0.9611 - val_loss: 0.1260 - val_doa_out_loss: 0.1016 - val_sed_out_loss: 0.2439 - val_doa_out_masked_mae: 24.2244 - val_doa_out_masked_mae2: 11.2262 - val_doa_out_masked_mae_original: 26.2986 - val_sed_out_custom_accuracy: 0.9316\n",
      "Epoch 48/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0936 - doa_out_loss: 0.0825 - sed_out_loss: 0.1105 - doa_out_masked_mae: 20.2425 - doa_out_masked_mae2: 10.3954 - doa_out_masked_mae_original: 22.5496 - sed_out_custom_accuracy: 0.9605\n",
      "Epoch 48: val_doa_out_masked_mae improved from 19.17259 to 19.17198, saving model to saved_doa_model/class_048.h5\n",
      "156/156 [==============================] - 165s 888ms/step - loss: 0.0936 - doa_out_loss: 0.0825 - sed_out_loss: 0.1105 - doa_out_masked_mae: 20.2425 - doa_out_masked_mae2: 10.3954 - doa_out_masked_mae_original: 22.5496 - sed_out_custom_accuracy: 0.9605 - val_loss: 0.1196 - val_doa_out_loss: 0.0868 - val_sed_out_loss: 0.3285 - val_doa_out_masked_mae: 19.1720 - val_doa_out_masked_mae2: 10.1722 - val_doa_out_masked_mae_original: 21.5551 - val_sed_out_custom_accuracy: 0.9106\n",
      "Epoch 49/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0941 - doa_out_loss: 0.0830 - sed_out_loss: 0.1104 - doa_out_masked_mae: 20.4194 - doa_out_masked_mae2: 10.5335 - doa_out_masked_mae_original: 22.7987 - sed_out_custom_accuracy: 0.9613\n",
      "Epoch 49: val_doa_out_masked_mae did not improve from 19.17198\n",
      "156/156 [==============================] - 183s 908ms/step - loss: 0.0941 - doa_out_loss: 0.0830 - sed_out_loss: 0.1104 - doa_out_masked_mae: 20.4194 - doa_out_masked_mae2: 10.5335 - doa_out_masked_mae_original: 22.7987 - sed_out_custom_accuracy: 0.9613 - val_loss: 0.1374 - val_doa_out_loss: 0.1167 - val_sed_out_loss: 0.2071 - val_doa_out_masked_mae: 27.0821 - val_doa_out_masked_mae2: 12.3802 - val_doa_out_masked_mae_original: 29.0943 - val_sed_out_custom_accuracy: 0.9435\n",
      "Epoch 50/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0917 - doa_out_loss: 0.0811 - sed_out_loss: 0.1060 - doa_out_masked_mae: 20.0449 - doa_out_masked_mae2: 10.4660 - doa_out_masked_mae_original: 22.2792 - sed_out_custom_accuracy: 0.9628\n",
      "Epoch 50: val_doa_out_masked_mae did not improve from 19.17198\n",
      "156/156 [==============================] - 168s 912ms/step - loss: 0.0917 - doa_out_loss: 0.0811 - sed_out_loss: 0.1060 - doa_out_masked_mae: 20.0449 - doa_out_masked_mae2: 10.4660 - doa_out_masked_mae_original: 22.2792 - sed_out_custom_accuracy: 0.9628 - val_loss: 0.1451 - val_doa_out_loss: 0.1169 - val_sed_out_loss: 0.2823 - val_doa_out_masked_mae: 26.5810 - val_doa_out_masked_mae2: 12.2284 - val_doa_out_masked_mae_original: 28.7249 - val_sed_out_custom_accuracy: 0.8975\n",
      "Epoch 51/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0902 - doa_out_loss: 0.0797 - sed_out_loss: 0.1053 - doa_out_masked_mae: 19.9189 - doa_out_masked_mae2: 10.2570 - doa_out_masked_mae_original: 22.2304 - sed_out_custom_accuracy: 0.9629\n",
      "Epoch 51: val_doa_out_masked_mae did not improve from 19.17198\n",
      "156/156 [==============================] - 181s 881ms/step - loss: 0.0902 - doa_out_loss: 0.0797 - sed_out_loss: 0.1053 - doa_out_masked_mae: 19.9189 - doa_out_masked_mae2: 10.2570 - doa_out_masked_mae_original: 22.2304 - sed_out_custom_accuracy: 0.9629 - val_loss: 0.1164 - val_doa_out_loss: 0.0972 - val_sed_out_loss: 0.1922 - val_doa_out_masked_mae: 21.2363 - val_doa_out_masked_mae2: 11.0966 - val_doa_out_masked_mae_original: 23.3347 - val_sed_out_custom_accuracy: 0.9293\n",
      "Epoch 52/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0886 - doa_out_loss: 0.0784 - sed_out_loss: 0.1011 - doa_out_masked_mae: 19.6940 - doa_out_masked_mae2: 10.1647 - doa_out_masked_mae_original: 21.8815 - sed_out_custom_accuracy: 0.9637\n",
      "Epoch 52: val_doa_out_masked_mae did not improve from 19.17198\n",
      "156/156 [==============================] - 166s 902ms/step - loss: 0.0886 - doa_out_loss: 0.0784 - sed_out_loss: 0.1011 - doa_out_masked_mae: 19.6940 - doa_out_masked_mae2: 10.1647 - doa_out_masked_mae_original: 21.8815 - sed_out_custom_accuracy: 0.9637 - val_loss: 0.1250 - val_doa_out_loss: 0.1008 - val_sed_out_loss: 0.2416 - val_doa_out_masked_mae: 19.5757 - val_doa_out_masked_mae2: 11.6426 - val_doa_out_masked_mae_original: 22.0464 - val_sed_out_custom_accuracy: 0.9301\n",
      "Epoch 53/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0887 - doa_out_loss: 0.0788 - sed_out_loss: 0.0997 - doa_out_masked_mae: 19.6808 - doa_out_masked_mae2: 10.1712 - doa_out_masked_mae_original: 21.8848 - sed_out_custom_accuracy: 0.9648\n",
      "Epoch 53: val_doa_out_masked_mae did not improve from 19.17198\n",
      "156/156 [==============================] - 165s 892ms/step - loss: 0.0887 - doa_out_loss: 0.0788 - sed_out_loss: 0.0997 - doa_out_masked_mae: 19.6808 - doa_out_masked_mae2: 10.1712 - doa_out_masked_mae_original: 21.8848 - sed_out_custom_accuracy: 0.9648 - val_loss: 0.1603 - val_doa_out_loss: 0.1282 - val_sed_out_loss: 0.3206 - val_doa_out_masked_mae: 25.5423 - val_doa_out_masked_mae2: 13.0782 - val_doa_out_masked_mae_original: 28.2512 - val_sed_out_custom_accuracy: 0.9234\n",
      "Epoch 54/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0877 - doa_out_loss: 0.0776 - sed_out_loss: 0.1013 - doa_out_masked_mae: 19.5489 - doa_out_masked_mae2: 9.9497 - doa_out_masked_mae_original: 21.8719 - sed_out_custom_accuracy: 0.9640\n",
      "Epoch 54: val_doa_out_masked_mae did not improve from 19.17198\n",
      "156/156 [==============================] - 166s 903ms/step - loss: 0.0877 - doa_out_loss: 0.0776 - sed_out_loss: 0.1013 - doa_out_masked_mae: 19.5489 - doa_out_masked_mae2: 9.9497 - doa_out_masked_mae_original: 21.8719 - sed_out_custom_accuracy: 0.9640 - val_loss: 0.1345 - val_doa_out_loss: 0.1157 - val_sed_out_loss: 0.1881 - val_doa_out_masked_mae: 22.2728 - val_doa_out_masked_mae2: 13.0697 - val_doa_out_masked_mae_original: 25.1159 - val_sed_out_custom_accuracy: 0.9424\n",
      "Epoch 55/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0864 - doa_out_loss: 0.0767 - sed_out_loss: 0.0966 - doa_out_masked_mae: 19.2014 - doa_out_masked_mae2: 10.0476 - doa_out_masked_mae_original: 21.4717 - sed_out_custom_accuracy: 0.9664\n",
      "Epoch 55: val_doa_out_masked_mae did not improve from 19.17198\n",
      "156/156 [==============================] - 164s 887ms/step - loss: 0.0864 - doa_out_loss: 0.0767 - sed_out_loss: 0.0966 - doa_out_masked_mae: 19.2014 - doa_out_masked_mae2: 10.0476 - doa_out_masked_mae_original: 21.4717 - sed_out_custom_accuracy: 0.9664 - val_loss: 0.1190 - val_doa_out_loss: 0.0952 - val_sed_out_loss: 0.2379 - val_doa_out_masked_mae: 21.5977 - val_doa_out_masked_mae2: 10.2962 - val_doa_out_masked_mae_original: 22.6560 - val_sed_out_custom_accuracy: 0.9166\n",
      "Epoch 56/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0860 - doa_out_loss: 0.0765 - sed_out_loss: 0.0953 - doa_out_masked_mae: 19.2534 - doa_out_masked_mae2: 9.9230 - doa_out_masked_mae_original: 21.3696 - sed_out_custom_accuracy: 0.9660\n",
      "Epoch 56: val_doa_out_masked_mae did not improve from 19.17198\n",
      "156/156 [==============================] - 182s 921ms/step - loss: 0.0860 - doa_out_loss: 0.0765 - sed_out_loss: 0.0953 - doa_out_masked_mae: 19.2534 - doa_out_masked_mae2: 9.9230 - doa_out_masked_mae_original: 21.3696 - sed_out_custom_accuracy: 0.9660 - val_loss: 0.1163 - val_doa_out_loss: 0.0915 - val_sed_out_loss: 0.2486 - val_doa_out_masked_mae: 22.1306 - val_doa_out_masked_mae2: 10.7596 - val_doa_out_masked_mae_original: 23.9640 - val_sed_out_custom_accuracy: 0.9379\n",
      "Epoch 57/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0837 - doa_out_loss: 0.0745 - sed_out_loss: 0.0924 - doa_out_masked_mae: 18.9529 - doa_out_masked_mae2: 9.8409 - doa_out_masked_mae_original: 21.1959 - sed_out_custom_accuracy: 0.9674\n",
      "Epoch 57: val_doa_out_masked_mae did not improve from 19.17198\n",
      "156/156 [==============================] - 167s 904ms/step - loss: 0.0837 - doa_out_loss: 0.0745 - sed_out_loss: 0.0924 - doa_out_masked_mae: 18.9529 - doa_out_masked_mae2: 9.8409 - doa_out_masked_mae_original: 21.1959 - sed_out_custom_accuracy: 0.9674 - val_loss: 0.1044 - val_doa_out_loss: 0.0857 - val_sed_out_loss: 0.1875 - val_doa_out_masked_mae: 19.9982 - val_doa_out_masked_mae2: 10.5596 - val_doa_out_masked_mae_original: 21.1160 - val_sed_out_custom_accuracy: 0.9434\n",
      "Epoch 58/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0845 - doa_out_loss: 0.0745 - sed_out_loss: 0.0997 - doa_out_masked_mae: 19.0181 - doa_out_masked_mae2: 9.7791 - doa_out_masked_mae_original: 21.2852 - sed_out_custom_accuracy: 0.9648\n",
      "Epoch 58: val_doa_out_masked_mae did not improve from 19.17198\n",
      "156/156 [==============================] - 172s 914ms/step - loss: 0.0845 - doa_out_loss: 0.0745 - sed_out_loss: 0.0997 - doa_out_masked_mae: 19.0181 - doa_out_masked_mae2: 9.7791 - doa_out_masked_mae_original: 21.2852 - sed_out_custom_accuracy: 0.9648 - val_loss: 0.1124 - val_doa_out_loss: 0.0931 - val_sed_out_loss: 0.1931 - val_doa_out_masked_mae: 26.6437 - val_doa_out_masked_mae2: 10.1045 - val_doa_out_masked_mae_original: 27.4689 - val_sed_out_custom_accuracy: 0.9468\n",
      "Epoch 59/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0830 - doa_out_loss: 0.0739 - sed_out_loss: 0.0914 - doa_out_masked_mae: 18.7416 - doa_out_masked_mae2: 9.8171 - doa_out_masked_mae_original: 20.8574 - sed_out_custom_accuracy: 0.9674\n",
      "Epoch 59: val_doa_out_masked_mae did not improve from 19.17198\n",
      "156/156 [==============================] - 168s 918ms/step - loss: 0.0830 - doa_out_loss: 0.0739 - sed_out_loss: 0.0914 - doa_out_masked_mae: 18.7416 - doa_out_masked_mae2: 9.8171 - doa_out_masked_mae_original: 20.8574 - sed_out_custom_accuracy: 0.9674 - val_loss: 0.1352 - val_doa_out_loss: 0.1121 - val_sed_out_loss: 0.2312 - val_doa_out_masked_mae: 22.2844 - val_doa_out_masked_mae2: 12.0302 - val_doa_out_masked_mae_original: 25.2018 - val_sed_out_custom_accuracy: 0.9163\n",
      "Epoch 60/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0823 - doa_out_loss: 0.0732 - sed_out_loss: 0.0915 - doa_out_masked_mae: 18.8655 - doa_out_masked_mae2: 9.7291 - doa_out_masked_mae_original: 20.9379 - sed_out_custom_accuracy: 0.9671\n",
      "Epoch 60: val_doa_out_masked_mae did not improve from 19.17198\n",
      "156/156 [==============================] - 164s 890ms/step - loss: 0.0823 - doa_out_loss: 0.0732 - sed_out_loss: 0.0915 - doa_out_masked_mae: 18.8655 - doa_out_masked_mae2: 9.7291 - doa_out_masked_mae_original: 20.9379 - sed_out_custom_accuracy: 0.9671 - val_loss: 0.1316 - val_doa_out_loss: 0.1099 - val_sed_out_loss: 0.2167 - val_doa_out_masked_mae: 24.4541 - val_doa_out_masked_mae2: 11.6201 - val_doa_out_masked_mae_original: 25.7497 - val_sed_out_custom_accuracy: 0.9191\n",
      "Epoch 61/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0810 - doa_out_loss: 0.0719 - sed_out_loss: 0.0908 - doa_out_masked_mae: 18.4340 - doa_out_masked_mae2: 9.6258 - doa_out_masked_mae_original: 20.5358 - sed_out_custom_accuracy: 0.9676\n",
      "Epoch 61: val_doa_out_masked_mae improved from 19.17198 to 18.89660, saving model to saved_doa_model/class_061.h5\n",
      "156/156 [==============================] - 194s 894ms/step - loss: 0.0810 - doa_out_loss: 0.0719 - sed_out_loss: 0.0908 - doa_out_masked_mae: 18.4340 - doa_out_masked_mae2: 9.6258 - doa_out_masked_mae_original: 20.5358 - sed_out_custom_accuracy: 0.9676 - val_loss: 0.1039 - val_doa_out_loss: 0.0782 - val_sed_out_loss: 0.2573 - val_doa_out_masked_mae: 18.8966 - val_doa_out_masked_mae2: 9.3118 - val_doa_out_masked_mae_original: 20.0016 - val_sed_out_custom_accuracy: 0.9176\n",
      "Epoch 62/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0806 - doa_out_loss: 0.0715 - sed_out_loss: 0.0910 - doa_out_masked_mae: 18.3808 - doa_out_masked_mae2: 9.5145 - doa_out_masked_mae_original: 20.4115 - sed_out_custom_accuracy: 0.9680\n",
      "Epoch 62: val_doa_out_masked_mae did not improve from 18.89660\n",
      "156/156 [==============================] - 169s 918ms/step - loss: 0.0806 - doa_out_loss: 0.0715 - sed_out_loss: 0.0910 - doa_out_masked_mae: 18.3808 - doa_out_masked_mae2: 9.5145 - doa_out_masked_mae_original: 20.4115 - sed_out_custom_accuracy: 0.9680 - val_loss: 0.1124 - val_doa_out_loss: 0.0905 - val_sed_out_loss: 0.2198 - val_doa_out_masked_mae: 22.2484 - val_doa_out_masked_mae2: 10.3088 - val_doa_out_masked_mae_original: 23.4582 - val_sed_out_custom_accuracy: 0.9270\n",
      "Epoch 63/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0789 - doa_out_loss: 0.0702 - sed_out_loss: 0.0863 - doa_out_masked_mae: 18.1420 - doa_out_masked_mae2: 9.5377 - doa_out_masked_mae_original: 20.2454 - sed_out_custom_accuracy: 0.9697\n",
      "Epoch 63: val_doa_out_masked_mae improved from 18.89660 to 16.92043, saving model to saved_doa_model/class_063.h5\n",
      "156/156 [==============================] - 166s 885ms/step - loss: 0.0789 - doa_out_loss: 0.0702 - sed_out_loss: 0.0863 - doa_out_masked_mae: 18.1420 - doa_out_masked_mae2: 9.5377 - doa_out_masked_mae_original: 20.2454 - sed_out_custom_accuracy: 0.9697 - val_loss: 0.0959 - val_doa_out_loss: 0.0791 - val_sed_out_loss: 0.1675 - val_doa_out_masked_mae: 16.9204 - val_doa_out_masked_mae2: 9.4873 - val_doa_out_masked_mae_original: 19.0493 - val_sed_out_custom_accuracy: 0.9535\n",
      "Epoch 64/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0785 - doa_out_loss: 0.0699 - sed_out_loss: 0.0859 - doa_out_masked_mae: 18.2043 - doa_out_masked_mae2: 9.4375 - doa_out_masked_mae_original: 20.3300 - sed_out_custom_accuracy: 0.9700\n",
      "Epoch 64: val_doa_out_masked_mae did not improve from 16.92043\n",
      "156/156 [==============================] - 170s 908ms/step - loss: 0.0785 - doa_out_loss: 0.0699 - sed_out_loss: 0.0859 - doa_out_masked_mae: 18.2043 - doa_out_masked_mae2: 9.4375 - doa_out_masked_mae_original: 20.3300 - sed_out_custom_accuracy: 0.9700 - val_loss: 0.1068 - val_doa_out_loss: 0.0856 - val_sed_out_loss: 0.2119 - val_doa_out_masked_mae: 19.0575 - val_doa_out_masked_mae2: 10.3251 - val_doa_out_masked_mae_original: 20.8059 - val_sed_out_custom_accuracy: 0.9201\n",
      "Epoch 65/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0779 - doa_out_loss: 0.0691 - sed_out_loss: 0.0879 - doa_out_masked_mae: 18.0087 - doa_out_masked_mae2: 9.4721 - doa_out_masked_mae_original: 20.0506 - sed_out_custom_accuracy: 0.9686\n",
      "Epoch 65: val_doa_out_masked_mae did not improve from 16.92043\n",
      "156/156 [==============================] - 168s 909ms/step - loss: 0.0779 - doa_out_loss: 0.0691 - sed_out_loss: 0.0879 - doa_out_masked_mae: 18.0087 - doa_out_masked_mae2: 9.4721 - doa_out_masked_mae_original: 20.0506 - sed_out_custom_accuracy: 0.9686 - val_loss: 0.1895 - val_doa_out_loss: 0.1711 - val_sed_out_loss: 0.1834 - val_doa_out_masked_mae: 39.5041 - val_doa_out_masked_mae2: 15.7185 - val_doa_out_masked_mae_original: 40.3376 - val_sed_out_custom_accuracy: 0.9346\n",
      "Epoch 66/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0774 - doa_out_loss: 0.0691 - sed_out_loss: 0.0834 - doa_out_masked_mae: 17.9109 - doa_out_masked_mae2: 9.3272 - doa_out_masked_mae_original: 20.0001 - sed_out_custom_accuracy: 0.9707\n",
      "Epoch 66: val_doa_out_masked_mae did not improve from 16.92043\n",
      "156/156 [==============================] - 176s 924ms/step - loss: 0.0774 - doa_out_loss: 0.0691 - sed_out_loss: 0.0834 - doa_out_masked_mae: 17.9109 - doa_out_masked_mae2: 9.3272 - doa_out_masked_mae_original: 20.0001 - sed_out_custom_accuracy: 0.9707 - val_loss: 0.1044 - val_doa_out_loss: 0.0829 - val_sed_out_loss: 0.2152 - val_doa_out_masked_mae: 20.1549 - val_doa_out_masked_mae2: 10.4797 - val_doa_out_masked_mae_original: 21.4860 - val_sed_out_custom_accuracy: 0.9138\n",
      "Epoch 67/250\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.0768 - doa_out_loss: 0.0682 - sed_out_loss: 0.0860 - doa_out_masked_mae: 17.9619 - doa_out_masked_mae2: 9.3153 - doa_out_masked_mae_original: 20.0006 - sed_out_custom_accuracy: 0.9697\n",
      "Epoch 67: val_doa_out_masked_mae did not improve from 16.92043\n",
      "156/156 [==============================] - 170s 910ms/step - loss: 0.0768 - doa_out_loss: 0.0682 - sed_out_loss: 0.0860 - doa_out_masked_mae: 17.9619 - doa_out_masked_mae2: 9.3153 - doa_out_masked_mae_original: 20.0006 - sed_out_custom_accuracy: 0.9697 - val_loss: 0.0995 - val_doa_out_loss: 0.0748 - val_sed_out_loss: 0.2463 - val_doa_out_masked_mae: 17.4177 - val_doa_out_masked_mae2: 8.9593 - val_doa_out_masked_mae_original: 18.9951 - val_sed_out_custom_accuracy: 0.9396\n",
      "Epoch 68/250\n",
      "115/156 [=====================>........] - ETA: 35s - loss: 0.0749 - doa_out_loss: 0.0667 - sed_out_loss: 0.0820 - doa_out_masked_mae: 17.5233 - doa_out_masked_mae2: 9.3120 - doa_out_masked_mae_original: 19.4971 - sed_out_custom_accuracy: 0.9713"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "########################\n",
    "### ACCDOA\n",
    "########################\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "@tf.function\n",
    "def tf_linear_sum_assignment(cost_matrix):\n",
    "    return tf.numpy_function(func=linear_sum_assignment,inp=[cost_matrix],Tout=[tf.int64,tf.int64])\n",
    "\n",
    "def accuracy_masked(y_gt, pred):\n",
    "    x = y_gt[:, :,:4] \n",
    "    y = y_gt[:, :,4:]\n",
    "    acc_true = tf.math.sqrt(x**2 + y**2) > 0.5\n",
    "    acc_true = K.cast(acc_true, 'float32')\n",
    "\n",
    "    x_ = pred[:, :,:4] \n",
    "    y_ = pred[:, :,4:]\n",
    "    acc_pred = tf.math.sqrt(x_**2 + y_**2) > 0.7\n",
    "    acc_pred = K.cast(acc_pred, 'float32')    \n",
    "    return tf.keras.metrics.categorical_accuracy(acc_true, acc_pred)\n",
    "\n",
    "def mae_masked_accdoa(y_gt, pred):\n",
    "    x = y_gt[:, :,:4] \n",
    "    y = y_gt[:, :,4:]\n",
    "    test = tf.math.sqrt(x**2 + y**2) > 0.6\n",
    "    test = tf.cast(test, tf.float32)\n",
    "    x_new = x * test\n",
    "    y_new = y * test\n",
    "    \n",
    "    x_ = pred[:, :,:4] \n",
    "    y_ = pred[:, :,4:]\n",
    "    x_new_ = x_ * test\n",
    "    y_new_ = y_ * test\n",
    "    \n",
    "    direction = tf.math.atan2(y_new_, x_new_) \n",
    "    direction = direction/tf.constant(math.pi)*180\n",
    "    direction2 = tf.math.atan2(y_new, x_new) \n",
    "    direction2 = direction2/tf.constant(math.pi)*180\n",
    "    return K.mean(K.abs(direction - direction2), -1)\n",
    "\n",
    "\n",
    "########################\n",
    "### DOA\n",
    "########################\n",
    "def masked_mse(y_gt, model_out):\n",
    "    sed_out = y_gt[:, :, 2:3] \n",
    "    sed_out = tf.concat([sed_out,sed_out], axis = 2)\n",
    "    x = K.square(model_out[:, :, :] - y_gt[:, :, :2])\n",
    "    return tf.reduce_sum(x * sed_out, 1)/(tf.reduce_sum(sed_out, 1) + 1e-7)\n",
    "\n",
    "def masked_mae(y_gt, model_out):\n",
    "    sed_out = y_gt[:, :, 2:3]  #TODO fix this hardcoded value of number of classes\n",
    "    sed_out = tf.cast(tf.concat([sed_out, sed_out], axis = 2), tf.float32)\n",
    "    direction = tf.math.atan2(model_out[:, :, 1:2],model_out[:, :, 0:1])\n",
    "    direction = direction/tf.constant(math.pi)*180 + 180\n",
    "    direction2 = tf.math.atan2(y_gt[:, :, 1:2], y_gt[:, :, 0:1])\n",
    "    direction2 = direction2/tf.constant(math.pi)*180 + 180\n",
    "    \n",
    "    \n",
    "    diff = direction2 - direction\n",
    "    weight = K.abs(diff)\n",
    "    fill_value_if_bigger = 360.-diff\n",
    "    threshold = 270.\n",
    "    weight = tf.where(tf.greater(diff, threshold), fill_value_if_bigger, diff)\n",
    "    weight = tf.abs(weight)\n",
    "    return tf.reduce_sum(weight * sed_out)/tf.reduce_sum(sed_out + 1e-7)\n",
    "\n",
    "\n",
    "\n",
    "def masked_mae2(y_gt, model_out):\n",
    "\n",
    "    sed_out = y_gt[:, :, 2:3]\n",
    "    sed_out = tf.concat([sed_out,sed_out], axis = 2)\n",
    "    direction = tf.math.atan2(model_out[:, :, 1:2], model_out[:, :, :1])\n",
    "    direction = direction/tf.constant(math.pi)*180\n",
    "    direction2 = tf.math.atan2(y_gt[:, :, 1:2], y_gt[:, :, :1])\n",
    "    direction2 = direction2/tf.constant(math.pi)*180\n",
    "    diff = direction2 - direction\n",
    "    diff = K.abs(diff) * sed_out\n",
    "    fill_value_if_bigger = 0.\n",
    "    threshold = 180.\n",
    "    weight = tf.where(tf.greater(diff, threshold), fill_value_if_bigger, diff)\n",
    "    \n",
    "    return K.mean(weight, -1)\n",
    "\n",
    "def masked_mae_original(y_gt, model_out):\n",
    "    sed_out = y_gt[:, :, 2:3]\n",
    "    sed_out = tf.concat([sed_out,sed_out], axis = 2)\n",
    "    direction = tf.math.atan2(model_out[:, :, 1:2], model_out[:, :, 0:1])\n",
    "    direction = direction/tf.constant(math.pi)*180\n",
    "    direction2 = tf.math.atan2(y_gt[:, :, 1:2], y_gt[:, :, 0:1])\n",
    "    direction2 = direction2/tf.constant(math.pi)*180\n",
    "    \n",
    "    \n",
    "    diff = direction2 - direction\n",
    "    weight = K.abs(diff)\n",
    "    # tf.print(tf.reduce_sum(sed_out))\n",
    "    return tf.reduce_sum(weight * sed_out)/tf.reduce_sum(sed_out + 1e-7)\n",
    "\n",
    "def custom_accuracy_categorical(y_true,y_pred):\n",
    "\n",
    "    y_true_class = K.argmax(y_true, axis=-1) + 1\n",
    "    y_pred_class = K.argmax(y_pred, axis=-1) + 1    \n",
    "    weight_ = tf.abs(y_true_class - y_pred_class)\n",
    "    weight = tf.cast(weight_, tf.int32)\n",
    "    weight = tf.where(tf.math.greater(weight_, 3),  0, weight)\n",
    "    weight = tf.where(tf.math.less_equal(weight_, 3),  1, weight)\n",
    "    \n",
    "    a = weight\n",
    "    \n",
    "    return K.mean(a)\n",
    "\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    mask = tf.not_equal(tf.reduce_max(y_true, -1), 0)\n",
    "    y_true = tf.boolean_mask(y_true, mask)\n",
    "    y_pred = tf.boolean_mask(y_pred, mask)\n",
    "    # y_true_class = K.argmax(y_true, axis=-1)\n",
    "    # y_pred_class = K.argmax(y_pred, axis=-1)\n",
    "\n",
    "    return tf.keras.metrics.categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "def accdoa_accuracy(y_true, y_pred):\n",
    "    y_pred = tf.math.sqrt(y_pred[:,:,:4]**2 + y_pred[:,:,4:]**2)\n",
    "    y_true = tf.math.sqrt(y_true[:,:,:4]**2 + y_true[:,:,4:]**2)\n",
    "    mask = tf.greater_equal(tf.reduce_max(y_true, -1), 0.5)\n",
    "    y_pred = tf.boolean_mask(y_pred, mask)\n",
    "    y_true = tf.boolean_mask(y_true, mask)\n",
    "    thus = tf.cast(tf.equal(tf.argmax(y_true, -1), tf.argmax(y_pred, -1)), tf.float32)\n",
    "    return tf.reduce_mean(thus)\n",
    "\n",
    "\n",
    "\n",
    "def categorical_weighted(target, output):\n",
    "    mask = tf.not_equal(tf.reduce_max(target, -1), 0)\n",
    "    y_true_c = tf.boolean_mask(target, mask)\n",
    "    y_pred_c = tf.boolean_mask(output, mask)\n",
    "    mask_b = tf.equal(tf.reduce_max(target, -1), 0)\n",
    "    y_true_b = tf.boolean_mask(target, mask_b)\n",
    "    y_pred_b = tf.boolean_mask(output, mask_b)\n",
    "\n",
    "    return tf.keras.losses.CategoricalCrossentropy(from_logits=False)(y_true_c, y_pred_c) + tf.keras.losses.BinaryCrossentropy(from_logits=False)(y_true_b, y_pred_b)\n",
    "\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('saved_doa_model/class_{epoch:03d}.h5', period=10) \n",
    "checkpoint2 = keras.callbacks.ModelCheckpoint('saved_doa_model/class_{epoch:03d}.h5', monitor='val_doa_out_masked_mae', verbose=1,\n",
    "                             save_best_only=True, save_weights_only=False,\n",
    "                             mode='auto', save_frequency=1) \n",
    "\n",
    "initial_learning_rate = 0.0001\n",
    "final_learning_rate = 0.000005\n",
    "learning_rate_decay_factor = (final_learning_rate / initial_learning_rate)**(1/500)\n",
    "steps_per_epoch = int(156)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                initial_learning_rate=initial_learning_rate,\n",
    "                decay_steps=steps_per_epoch,\n",
    "                decay_rate=learning_rate_decay_factor,\n",
    "                staircase=True)\n",
    "\n",
    "\n",
    "print(\"============== MODEL TRAINING ==============\")\n",
    "\n",
    "# AZIMUTH\n",
    "keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "\n",
    "\n",
    "model = keras_model_doa.get_model_newest((256,128,7), dropout_rate=0., nb_cnn2d_filt=128, f_pool_size=[8, 8, 4], t_pool_size=[1, 1, 1],\n",
    "              rnn_size=[128, 128], fnn_size=[128], output = 2, activation='tanh')\n",
    "\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss = {'doa_out':masked_mse, 'sed_out':categorical_weighted},\n",
    "              metrics= {'doa_out':[masked_mae, masked_mae2, masked_mae_original], 'sed_out':[custom_accuracy]}, loss_weights=[1, 0.1])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Load Checkpoint\n",
    "\n",
    "history = model.fit(data_train,\n",
    "                    epochs=250,\n",
    "                    verbose=1,\n",
    "                    validation_data = data_val,\n",
    "                    callbacks = [checkpoint, checkpoint2])\n",
    "\n",
    "# history = model.evaluate(data_val)\n",
    "\n",
    "model.save('saved_doa_model/first_model.h5')\n",
    "pd.DataFrame.from_dict(model.history.history).to_csv(f'unet_model_orm/history/first_model.csv',index=False)\n",
    "\n",
    "\n",
    "com.logger.info(\"save_model -> {}\".format('unet_model_wind/leveraging_elu.h5'))\n",
    "\n",
    "print(\"============== END TRAINING ==============\")\n",
    "\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d58e222-275a-4398-ac37-36fcac2c32f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bccd80-7244-4a4a-afda-493e2db73552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
