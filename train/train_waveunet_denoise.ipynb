{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aaa9ed5-01af-4441-92fb-56331ae10488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/usr/local/lib/python3.9/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/usr/local/lib/python3.9/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl5mutexC1Ev']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/usr/local/lib/python3.9/dist-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/usr/local/lib/python3.9/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/usr/local/lib/python3.9/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# import default libraries\n",
    "########################################################################\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "########################################################################\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# import additional libraries\n",
    "########################################################################\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "# from import\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    from sklearn.externals import joblib\n",
    "except:\n",
    "    import joblib\n",
    "# original lib\n",
    "import keras_model_unet_1D\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import librosa as lb\n",
    "import keras.backend as K\n",
    "import common as com\n",
    "from __future__ import division \n",
    "import numpy as np\n",
    "import scipy.signal as sps\n",
    "import scipy.io.wavfile as wf\n",
    "from sklearn.cluster import KMeans\n",
    "import sys\n",
    "import keras_model_uformer\n",
    "import cv2\n",
    "from scipy.signal import butter,sosfilt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow_io as tfio\n",
    "############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d58f89a-ebd2-4249-9dcf-a2511b8b2013",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# load parameter.yaml\n",
    "########################################################################\n",
    "param = com.yaml_load()\n",
    "########################################################################\n",
    "saved_weight = os.path.join(param[\"P_MODELSAVE\"], 'dataweights.{epoch:02d}-{val_dense_1_binary_accuracy:.2f}.hdf5')\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor = 'val_mask_loss', patience = 10)\n",
    "# model_unet = keras_model.get_model(input_shape=(1,param[\"feature\"][\"n_mels\"],param[\"feature\"][\"n_frames\"]), lr = param[\"fit\"][\"lr\"])\n",
    "\n",
    "import warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28973c70-c9fb-4aeb-95d7-ec475b18e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# get data from the list for file paths\n",
    "########################################################################\n",
    "def get_label(file_path):\n",
    "  # Convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    parts = tf.strings.split(parts[-1], sep='-')\n",
    "    return parts[0]\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    sos = butter(order, [low, high], analog=False, btype='band', output='sos')\n",
    "    return sos\n",
    "\n",
    "def butter_bandpass_filter(data):\n",
    "    lowcut = 1550\n",
    "    highcut = 22050/2 - 5\n",
    "    fs = 22050\n",
    "    order = 5\n",
    "    sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = sosfilt(sos, data)\n",
    "    return y\n",
    "\n",
    "def file_read(clean_path, combined_path, part=0):\n",
    "    \"\"\"\n",
    "    convert file_name to a vector array.\n",
    "\n",
    "    file_name : str\n",
    "        target .wav file\n",
    "\n",
    "    return : numpy.array( numpy.array( float ) )\n",
    "        vector array\n",
    "        * dataset.shape = (dataset_size, feature_vector_length)\n",
    "    \"\"\"\n",
    "    # generate clean audio data using tf.io\n",
    "    clean_contents = tf.io.read_file(clean_path)\n",
    "    clean, sr = tf.audio.decode_wav(clean_contents)\n",
    "    # clean = tf.transpose(tf.py_function(butter_bandpass_filter, [tf.transpose(clean)], (tf.float32)))\n",
    "    clean = tf.unstack(clean, axis=-1, num=4)\n",
    "    dic = {\"1\": [0, 1, 2, 3], \"2\": [2, 1, 0, 3], \"3\": [2, 3, 0, 1], \"4\": [0, 3, 2, 1]}\n",
    "\n",
    "    clean   = tf.stack([clean[dic[part][0]], clean[dic[part][1]],\n",
    "                        clean[dic[part][2]], clean[dic[part][3]]], axis=-1)\n",
    "\n",
    "    \n",
    "    # generate combined audio data using tf.io\n",
    "    combined_contents = tf.io.read_file(combined_path)\n",
    "    combined, sr = tf.audio.decode_wav(combined_contents)\n",
    "    combined = tf.unstack(combined, axis=-1, num=4)\n",
    "    \n",
    "    combined   = tf.stack([combined[dic[part][0]], combined[dic[part][1]],\n",
    "                           combined[dic[part][2]], combined[dic[part][3]]], axis=-1)\n",
    "    return combined, clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8121331-1f7f-4b94-bca2-add960ba7a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================\n",
      "============== DATASET_GENERATOR ==============\n",
      "tf.Tensor(8151, shape=(), dtype=int64)\n",
      "tf.Tensor(404, shape=(), dtype=int64)\n",
      "tf.Tensor(8151, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "type_ = \"topm_real\"\n",
    "type_2 = \"topm\"\n",
    "combined_loc = f\"dev_data_doa/combined_ground_truth_{type_}/train/\"\n",
    "clean_loc_train = f\"dev_data_filtering/anomaly_ground_truth_topm/Train/\"\n",
    "\n",
    "df = pd.read_csv(f\"dev_data_doa/combined_ground_truth_{type_}/train_combined_extra.csv\")\n",
    "df['anomaly_name'] = clean_loc_train + df['anomaly_name'].astype(str) + \".wav\"\n",
    "df['combined_name'] = combined_loc + df['combined_name'].astype(str) \n",
    "#TEST\n",
    "combined_loc_test = f\"dev_data_doa/combined_ground_truth_topm_real/test/\"\n",
    "clean_loc_test = f\"dev_data_filtering/anomaly_ground_truth_topm/Test/\"\n",
    "\n",
    "\n",
    "jk = pd.read_csv(f\"dev_data_doa/combined_ground_truth_topm_real/val_combined_extra.csv\")\n",
    "jk['anomaly_name'] = clean_loc_test + jk['anomaly_name'].astype(str) + \".wav\"\n",
    "jk['combined_name'] = combined_loc_test + jk['combined_name'].astype(str) \n",
    "\n",
    "jk_train = jk.sample(frac = 0.5, random_state=42)\n",
    "jk_val = jk.drop(jk_train.index)\n",
    "\n",
    "jk = pd.concat([jk_val], ignore_index=True)\n",
    "jk_combined_test = jk.pop(\"combined_name\")\n",
    "jk_clean_test = jk.pop(\"anomaly_name\")\n",
    "\n",
    "# loop of the base directory\n",
    "print(\"\\n===========================\")\n",
    "\n",
    "# generate dataset\n",
    "print(\"============== DATASET_GENERATOR ==============\")\n",
    "df = pd.concat([df], ignore_index=True)\n",
    "df_clean_train = df.pop(\"anomaly_name\")\n",
    "df_combined_train = df.pop(\"combined_name\")\n",
    "\n",
    "# first_data_real = /tmp/cache\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((df_clean_train, df_combined_train))\n",
    "train_dataset = train_dataset\n",
    "print(train_dataset.cardinality())\n",
    "\n",
    "data_train1 = train_dataset.map(lambda x,y: file_read(x,y, part=\"1\"))\n",
    "data_train2 = train_dataset.map(lambda x,y: file_read(x,y, part=\"2\"))\n",
    "data_train3 = train_dataset.map(lambda x,y: file_read(x,y, part=\"3\"))\n",
    "data_train = data_train1.concatenate(data_train2).concatenate(data_train3).cache(\"tmp_wave1/cache\").shuffle(1000).batch(BATCH_SIZE, drop_remainder=True).prefetch(1)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((jk_clean_test, jk_combined_test))\n",
    "val_dataset = val_dataset\n",
    "\n",
    "data_val1 = val_dataset.map(lambda x,y: file_read(x,y, part=\"1\"))\n",
    "print(data_val1.cardinality())\n",
    "\n",
    "data_val = data_val1.cache(\"tmp_wave2/cache\").shuffle(100).batch(BATCH_SIZE, drop_remainder=True).prefetch(1)\n",
    "\n",
    "print(data_train1.cardinality())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73df497e-f8e0-4683-91fa-a4c0600c57a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_SDR_loss(true, pred, eps = 1e-8):\n",
    "    num = K.sum(true * pred)\n",
    "    den = K.sqrt(K.sum(true * true)) * K.sqrt(K.sum(pred * pred))\n",
    "    return -(num / (den +eps))\n",
    "\n",
    "def mel_band(data):\n",
    "    bandpass = butter_bandpass_filter(data.numpy(), 1550, 22050/2-5, 22050)\n",
    "    mel_spec = lb.feature.melspectrogram(y=bandpass, n_fft=2048, hop_length=331, n_mels=128, center=False, fmin=0,\n",
    "                                                fmax=22050/2)\n",
    "    return mel_spec\n",
    "\n",
    "def stft_loss(y_true, y_pred):\n",
    "    n_fft=1024\n",
    "    hop_length=256\n",
    "    power=2.0\n",
    "    sr=22050\n",
    "    n=0\n",
    "    # True mel\n",
    "    true = tf.zeros([1, 513, 173, 4])\n",
    "    pred = tf.zeros([1, 513, 173, 4])\n",
    "\n",
    "\n",
    "    for y_true_ in y_true:\n",
    "        tf.autograph.experimental.set_loop_options(\n",
    "            shape_invariants=[(true, tf.TensorShape([None, 513, 173, 4]))]\n",
    "        )\n",
    "        y_true_ = tf.transpose(y_true_)\n",
    "        spectrogram_true_ = tfio.audio.spectrogram(y_true_, nfft=n_fft, window=n_fft, stride=hop_length)\n",
    "        spectrogram_true_ = tf.transpose(spectrogram_true_)\n",
    "        spectrogram_true_ = tf.expand_dims(spectrogram_true_, 0)\n",
    "        true = tf.concat([true, spectrogram_true_], 0)\n",
    "        \n",
    "    for y_pred_ in y_pred:\n",
    "        tf.autograph.experimental.set_loop_options(\n",
    "            shape_invariants=[(pred, tf.TensorShape([None, 513, 173, 4]))]\n",
    "        )\n",
    "        y_pred_ = tf.transpose(y_pred_)\n",
    "        spectrogram_pred_ = tfio.audio.spectrogram(y_pred_, nfft=n_fft, window=n_fft, stride=hop_length)\n",
    "        spectrogram_pred_ = tf.transpose(spectrogram_pred_)\n",
    "        spectrogram_pred_ = tf.expand_dims(spectrogram_pred_, 0)\n",
    "        \n",
    "        pred = tf.concat([pred, spectrogram_pred_], 0)\n",
    "        \n",
    "    mel = K.square(pred - true)\n",
    "    loss = tf.reduce_mean(mel)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def test(y_true, y_pred):\n",
    "    n_mels=128\n",
    "    n_fft=2823\n",
    "    hop_length=330\n",
    "    power=2.0\n",
    "    sr=22050\n",
    "    # True mel\n",
    "    y_true = tf.transpose(y_true)\n",
    "    spectrogram_true = tfio.audio.spectrogram(y_true, nfft=n_fft, window=n_fft, stride=hop_length)\n",
    "    mel_spectrogram_true = tfio.audio.melscale(spectrogram_true, sr, mels=n_mels, fmin=0, fmax=11025, name=None)\n",
    "    dbscale_mel_spectrogram_true = tfio.audio.dbscale(mel_spectrogram_true, top_db=80)\n",
    "\n",
    "    # Pred mel\n",
    "    y_pred = tf.transpose(y_pred)\n",
    "    spectrogram_pred = tfio.audio.spectrogram(y_pred, nfft=n_fft, window=n_fft, stride=hop_length)\n",
    "    mel_spectrogram_pred = tfio.audio.melscale(spectrogram_pred, sr, mels=n_mels, fmin=0, fmax=11025, name=None)\n",
    "    dbscale_mel_spectrogram_pred = tfio.audio.dbscale(mel_spectrogram_pred, top_db=80)\n",
    "\n",
    "    true = tf.clip_by_value(dbscale_mel_spectrogram_true, 1e-7, 1e3)\n",
    "    pred = tf.clip_by_value(dbscale_mel_spectrogram_pred, 1e-7, 1e3)\n",
    "    # Calculate spectral loss\n",
    "    result = K.square(pred - true)\n",
    "    return result\n",
    "\n",
    "def weighted_SDR_loss(true, pred):\n",
    "    noisy_speech = true[:,:,4:]\n",
    "    pred_speech = pred\n",
    "    true_speech = true[:,:,:4]\n",
    "    \n",
    "    def SDR_loss (pred, true, eps = 1e-8):\n",
    "        num = K.sum(pred * true)\n",
    "        den = K.sqrt(K.sum(true * true)) * K.sqrt(K.sum(pred * pred))\n",
    "        return -(num / (den + eps))\n",
    "\n",
    "    pred_noise = noisy_speech - pred_speech\n",
    "    true_noise = noisy_speech - true_speech\n",
    "    alpha      = K.sum(true_speech**2) / (K.sum(true_speech**2) + K.sum(true_noise**2)) \n",
    "    sound_SDR = SDR_loss(pred_speech, true_speech)\n",
    "    noise_SDR = SDR_loss(pred_noise, true_noise)\n",
    "    return alpha * sound_SDR + (1-alpha) * noise_SDR + custom_mse(true, pred)\n",
    "\n",
    "def spectral_loss_mel(y_true, y_pred):\n",
    "    n_mels=128\n",
    "    n_fft=2048\n",
    "    hop_length=345\n",
    "    power=2.0\n",
    "    sr=22050\n",
    "    n=0\n",
    "    # True mel\n",
    "    true = tf.zeros([1, 128, 128, 2])\n",
    "    pred = tf.zeros([1, 128, 128, 2])\n",
    "    pred_speech = y_pred\n",
    "    true_speech = y_true[:,:,:2]\n",
    "\n",
    "    for y_true_ in true_speech:\n",
    "        tf.autograph.experimental.set_loop_options(\n",
    "            shape_invariants=[(true, tf.TensorShape([None, 128, None, 2]))]\n",
    "        )\n",
    "        y_true_ = tf.transpose(y_true_)\n",
    "        spectrogram_true = tfio.audio.spectrogram(y_true_, nfft=n_fft, window=n_fft, stride=hop_length)\n",
    "        spectrogram_true_ = tfio.audio.melscale(spectrogram_true, sr, mels=n_mels, fmin=0, fmax=11025, name=None)\n",
    "        spectrogram_true_ = tf.transpose(spectrogram_true_)\n",
    "        spectrogram_true_ = tfio.audio.dbscale(spectrogram_true_, top_db=80)\n",
    "        spectrogram_true_ = tf.expand_dims(spectrogram_true_, 0)\n",
    "        \n",
    "        true = tf.concat([true, spectrogram_true_], 0)\n",
    "        \n",
    "    for y_pred_ in pred_speech:\n",
    "        tf.autograph.experimental.set_loop_options(\n",
    "            shape_invariants=[(pred, tf.TensorShape([None, 128, None, 2]))]\n",
    "        )\n",
    "        y_pred_ = tf.transpose(y_pred_)\n",
    "        spectrogram_pred = tfio.audio.spectrogram(y_pred_, nfft=n_fft, window=n_fft, stride=hop_length)\n",
    "        spectrogram_pred_ = tfio.audio.melscale(spectrogram_pred, sr, mels=n_mels, fmin=0, fmax=11025, name=None)\n",
    "        spectrogram_pred_ = tf.transpose(spectrogram_pred_)\n",
    "        spectrogram_pred_ = tfio.audio.dbscale(spectrogram_pred_, top_db=80)\n",
    "        spectrogram_pred_ = tf.expand_dims(spectrogram_pred_, 0)\n",
    "        \n",
    "        pred = tf.concat([pred, spectrogram_pred_], 0)\n",
    "        \n",
    "    # l1 = tf.reduce_mean(K.abs(y_pred - y_true))\n",
    "    # l1 = weighted_SDR_loss(y_true, y_pred)\n",
    "    mel = K.square(pred - true)\n",
    "    l2 = tf.reduce_mean(mel)\n",
    "    # l3 = stft_loss(y_true, y_pred)\n",
    "    return l2\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "def custom_mse(y_true, y_pred):\n",
    "    \n",
    "    return K.mean(K.square(y_pred - y_true[:,:,:4]), -1)\n",
    "\n",
    "def custom_mae(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true[:,:,:4]), -1)\n",
    "    \n",
    "def SDR_metric(y_true, y_pred):\n",
    "    n_mels=128\n",
    "    n_fft=2048\n",
    "    hop_length=345\n",
    "    power=2.0\n",
    "    sr=22050\n",
    "    n=0\n",
    "    # True mel\n",
    "    true = tf.zeros([1, 128, 128, 4])\n",
    "    pred = tf.zeros([1, 128, 128, 4])\n",
    "    pred_speech = y_pred\n",
    "    true_speech = y_true[:,:,:4]        \n",
    "    # l1 = tf.reduce_mean(K.abs(y_pred - y_true))\n",
    "    l1 = weighted_SDR_loss(y_true, y_pred)\n",
    "    return l1\n",
    "\n",
    "@tf.function\n",
    "def SALSA(audio, fs=22050, n_fft=1024, hop_length=345\n",
    "          , feature_type = 'salsa_lite'):\n",
    "    audio_input = audio\n",
    "    # Compute stft\n",
    "    n_mics = 4\n",
    "    n_bins = n_fft // 2 + 1\n",
    "    fmax = 6050  # Hz\n",
    "    fmin_doa = 520\n",
    "    fmax_doa = 6050\n",
    "    lower_bin = tf.cast(tf.math.floor(fmin_doa * n_fft / tf.cast(fs, tf.float32)), tf.int32)  # 512: 1; 256: 0\n",
    "    upper_bin = tf.cast(tf.math.floor(fmax_doa * n_fft / tf.cast(fs, tf.float32)), tf.int32)  # 9000Hz: 512: 192, 256: 96\n",
    "    cutoff_bin = tf.cast(tf.math.floor(fmax * n_fft / tf.cast(fs, tf.float32)), tf.int32)  # 9000 Hz, 512 nfft: cutoff_bin = 192\n",
    "    c = 343\n",
    "    delta = 2 * math.pi * fs / (n_fft * c)\n",
    "    freq_vector = tf.experimental.numpy.arange(n_bins)\n",
    "    mask = tf.cast(tf.equal(freq_vector, 0), tf.float32)\n",
    "    freq_vector = tf.cast(freq_vector, tf.float32)+mask\n",
    "    freq_vector = freq_vector[:, None, None]  # n_bins x 1 x 1\n",
    "    lower_bin = tf.maximum(1, lower_bin)\n",
    "    log_specs = tf.zeros([n_fft//2+1,128, 1])\n",
    "    X = tf.zeros([n_fft//2+1,128, 1], dtype=tf.complex64)\n",
    "    \n",
    "    for imic in np.arange(4):\n",
    "        tf.autograph.experimental.set_loop_options(\n",
    "            shape_invariants=[(X, tf.TensorShape([None, 128, n_fft//2+1]))]\n",
    "                )\n",
    "        tf.autograph.experimental.set_loop_options(\n",
    "            shape_invariants=[(log_specs, tf.TensorShape([None, 128, n_fft//4+1]))]\n",
    "                )\n",
    "\n",
    "        stft = (tf.signal.stft(audio_input[imic, :], frame_length=n_fft, frame_step=hop_length, window_fn=tf.signal.hann_window, pad_end=True))\n",
    "        X = tf.concat([X, tf.transpose(tf.expand_dims(stft, 0))], -1)\n",
    "\n",
    "    log_specs = log_specs[:,:,1:]\n",
    "    X = X[:,:,1:]\n",
    "    # Compute spatial feature\n",
    "    phase_vector = tf.math.angle(X[:, :, 1:] * tf.math.conj(X[:, :, 0, None])+tf.complex(0., 1e-7))\n",
    "    \n",
    "#     # phase_vector = phase_vector / math.pi\n",
    "    phase_vector = phase_vector / (delta * freq_vector)\n",
    "    phase_vector = tf.transpose(phase_vector, [2, 1, 0])\n",
    "    X = tf.transpose(tf.abs(X), [2, 1, 0])\n",
    "# #     # Crop frequency\n",
    "    log_specs = X[:, :, lower_bin:cutoff_bin]\n",
    "    phase_vector = phase_vector[:, :, lower_bin:cutoff_bin]\n",
    "    phase_vector = phase_vector\n",
    "    \n",
    "#     # Stack features\n",
    "    audio_feature = tf.concat([log_specs, phase_vector], axis=0)\n",
    "    return audio_feature\n",
    "\n",
    "def SALSA_loss(y_true, y_pred):\n",
    "    true = tf.zeros([1, 256, 128, 7])\n",
    "    pred = tf.zeros([1, 256, 128, 7])\n",
    "    pred_speech = y_pred\n",
    "    true_speech = y_true[:,:,:4]\n",
    "\n",
    "    \n",
    "    for y_true_ in true_speech:\n",
    "        tf.autograph.experimental.set_loop_options(\n",
    "            shape_invariants=[(true, tf.TensorShape([None, 256, 128, None]))]\n",
    "        )\n",
    "        y_true_ = tf.transpose(y_true_)\n",
    "        salsa_true_ = SALSA(y_true_)\n",
    "        spectrogram_true_ = tf.transpose(salsa_true_)\n",
    "        spectrogram_true_ = tf.expand_dims(spectrogram_true_, 0)\n",
    "        true = tf.concat([true, spectrogram_true_], 0)\n",
    "\n",
    "        \n",
    "    for y_pred_ in pred_speech:\n",
    "        tf.autograph.experimental.set_loop_options(\n",
    "            shape_invariants=[(pred, tf.TensorShape([None, 256, 128, None]))]\n",
    "        )\n",
    "        y_pred_ = tf.transpose(y_pred_)\n",
    "        salsa_pred_ = SALSA(y_pred_)\n",
    "        spectrogram_pred_ = tf.transpose(salsa_pred_)\n",
    "        spectrogram_pred_ = tf.expand_dims(spectrogram_pred_, 0)\n",
    "        \n",
    "        pred = tf.concat([pred, spectrogram_pred_], 0)\n",
    "\n",
    "    mel = K.square(pred - true)\n",
    "    l5 = tf.reduce_mean(mel[:,:,:,:])\n",
    "    l3 = tf.reduce_mean(K.square(y_pred - y_true[:,:,:4]))\n",
    "    return l3+l5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73459356-bd64-46c1-987f-90d6ea8f473e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " raw_input (InputLayer)         [(None, 44100, 4)]   0           []                               \n",
      "                                                                                                  \n",
      " exp_dims_0 (Lambda)            (None, 1, 44100, 4)  0           ['raw_input[0][0]']              \n",
      "                                                                                                  \n",
      " bilinear_interpol_0 (Lambda)   (None, 1, 32768, 4)  0           ['exp_dims_0[0][0]']             \n",
      "                                                                                                  \n",
      " bilinear_interpol_1 (Lambda)   (None, 1, 65536, 4)  0           ['bilinear_interpol_0[0][0]']    \n",
      "                                                                                                  \n",
      " bilinear_interpol_2 (Lambda)   (None, 1, 131072, 4  0           ['bilinear_interpol_1[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " sq_dims_0 (Lambda)             (None, 131072, 4)    0           ['bilinear_interpol_2[0][0]']    \n",
      "                                                                                                  \n",
      " Down_Conv_0 (Conv1D)           (None, 32768, 64)    2112        ['sq_dims_0[0][0]']              \n",
      "                                                                                                  \n",
      " Down_Conv_Activ_0 (ReLU)       (None, 32768, 64)    0           ['Down_Conv_0[0][0]']            \n",
      "                                                                                                  \n",
      " Down_Conv_2_0 (Conv1D)         (None, 32768, 64)    4160        ['Down_Conv_Activ_0[0][0]']      \n",
      "                                                                                                  \n",
      " glu_down0 (GLU)                (None, 32768, 32)    0           ['Down_Conv_2_0[0][0]']          \n",
      "                                                                                                  \n",
      " Down_Conv_1 (Conv1D)           (None, 8192, 128)    32896       ['glu_down0[0][0]']              \n",
      "                                                                                                  \n",
      " Down_Conv_Activ_1 (ReLU)       (None, 8192, 128)    0           ['Down_Conv_1[0][0]']            \n",
      "                                                                                                  \n",
      " Down_Conv_2_1 (Conv1D)         (None, 8192, 128)    16512       ['Down_Conv_Activ_1[0][0]']      \n",
      "                                                                                                  \n",
      " glu_down1 (GLU)                (None, 8192, 64)     0           ['Down_Conv_2_1[0][0]']          \n",
      "                                                                                                  \n",
      " Down_Conv_2 (Conv1D)           (None, 2048, 256)    131328      ['glu_down1[0][0]']              \n",
      "                                                                                                  \n",
      " Down_Conv_Activ_2 (ReLU)       (None, 2048, 256)    0           ['Down_Conv_2[0][0]']            \n",
      "                                                                                                  \n",
      " Down_Conv_2_2 (Conv1D)         (None, 2048, 256)    65792       ['Down_Conv_Activ_2[0][0]']      \n",
      "                                                                                                  \n",
      " glu_down2 (GLU)                (None, 2048, 128)    0           ['Down_Conv_2_2[0][0]']          \n",
      "                                                                                                  \n",
      " Down_Conv_3 (Conv1D)           (None, 512, 512)     524800      ['glu_down2[0][0]']              \n",
      "                                                                                                  \n",
      " Down_Conv_Activ_3 (ReLU)       (None, 512, 512)     0           ['Down_Conv_3[0][0]']            \n",
      "                                                                                                  \n",
      " Down_Conv_2_3 (Conv1D)         (None, 512, 512)     262656      ['Down_Conv_Activ_3[0][0]']      \n",
      "                                                                                                  \n",
      " glu_down3 (GLU)                (None, 512, 256)     0           ['Down_Conv_2_3[0][0]']          \n",
      "                                                                                                  \n",
      " conformer_block (ConformerBloc  (None, 512, 256)    2302528     ['glu_down3[0][0]']              \n",
      " k)                                                                                               \n",
      "                                                                                                  \n",
      " conformer_block_1 (ConformerBl  (None, 512, 256)    2302528     ['conformer_block[0][0]']        \n",
      " ock)                                                                                             \n",
      "                                                                                                  \n",
      " crop_layer_0 (CropLayer)       (None, 512, 256)     0           ['conformer_block_1[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_0 (Concatenate)    (None, 512, 512)     0           ['crop_layer_0[0][0]',           \n",
      "                                                                  'glu_down3[0][0]']              \n",
      "                                                                                                  \n",
      " Up_Conv_0 (Conv1D)             (None, 512, 512)     262656      ['concatenate_0[0][0]']          \n",
      "                                                                                                  \n",
      " glu_up0 (GLU)                  (None, 512, 256)     0           ['Up_Conv_0[0][0]']              \n",
      "                                                                                                  \n",
      " Up_Conv_Activ_0 (ReLU)         (None, 512, 256)     0           ['glu_up0[0][0]']                \n",
      "                                                                                                  \n",
      " Up_Conv_Trans0 (Conv1DTranspos  (None, 2048, 512)   1049088     ['Up_Conv_Activ_0[0][0]']        \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " crop_layer_1 (CropLayer)       (None, 2048, 512)    0           ['Up_Conv_Trans0[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 2048, 640)    0           ['crop_layer_1[0][0]',           \n",
      "                                                                  'glu_down2[0][0]']              \n",
      "                                                                                                  \n",
      " Up_Conv_1 (Conv1D)             (None, 2048, 256)    164096      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " glu_up1 (GLU)                  (None, 2048, 128)    0           ['Up_Conv_1[0][0]']              \n",
      "                                                                                                  \n",
      " Up_Conv_Activ_1 (ReLU)         (None, 2048, 128)    0           ['glu_up1[0][0]']                \n",
      "                                                                                                  \n",
      " Up_Conv_Trans1 (Conv1DTranspos  (None, 8192, 256)   262400      ['Up_Conv_Activ_1[0][0]']        \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " crop_layer_2 (CropLayer)       (None, 8192, 256)    0           ['Up_Conv_Trans1[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 8192, 320)    0           ['crop_layer_2[0][0]',           \n",
      "                                                                  'glu_down1[0][0]']              \n",
      "                                                                                                  \n",
      " Up_Conv_2 (Conv1D)             (None, 8192, 128)    41088       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " glu_up2 (GLU)                  (None, 8192, 64)     0           ['Up_Conv_2[0][0]']              \n",
      "                                                                                                  \n",
      " Up_Conv_Activ_2 (ReLU)         (None, 8192, 64)     0           ['glu_up2[0][0]']                \n",
      "                                                                                                  \n",
      " Up_Conv_Trans2 (Conv1DTranspos  (None, 32768, 128)  65664       ['Up_Conv_Activ_2[0][0]']        \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " crop_layer_3 (CropLayer)       (None, 32768, 128)   0           ['Up_Conv_Trans2[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 32768, 160)   0           ['crop_layer_3[0][0]',           \n",
      "                                                                  'glu_down0[0][0]']              \n",
      "                                                                                                  \n",
      " Up_Conv_3 (Conv1D)             (None, 32768, 64)    10304       ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " glu_up3 (GLU)                  (None, 32768, 32)    0           ['Up_Conv_3[0][0]']              \n",
      "                                                                                                  \n",
      " Up_Conv_Activ_3 (ReLU)         (None, 32768, 32)    0           ['glu_up3[0][0]']                \n",
      "                                                                                                  \n",
      " Up_Conv_Trans3 (Conv1DTranspos  (None, 131072, 64)  16448       ['Up_Conv_Activ_3[0][0]']        \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " crop_layer_4 (CropLayer)       (None, 131072, 4)    0           ['sq_dims_0[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 131072, 68)   0           ['Up_Conv_Trans3[0][0]',         \n",
      "                                                                  'crop_layer_4[0][0]']           \n",
      "                                                                                                  \n",
      " audio_clip_0 (AudioClipLayer)  (None, 131072, 68)   0           ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " independent_out (IndependentOu  (None, 131072, 4)   276         ['audio_clip_0[0][0]']           \n",
      " tputLayer)                                                                                       \n",
      "                                                                                                  \n",
      " exp_dims_1 (Lambda)            (None, 1, 131072, 4  0           ['independent_out[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bilinear_interpol_down0 (Lambd  (None, 1, 65536, 4)  0          ['exp_dims_1[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " bilinear_interpol_down1 (Lambd  (None, 1, 32768, 4)  0          ['bilinear_interpol_down0[0][0]']\n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " bilinear_interpol_down2 (Lambd  (None, 1, 44100, 4)  0          ['bilinear_interpol_down1[0][0]']\n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " sq_dims_1 (Lambda)             (None, 44100, 4)     0           ['bilinear_interpol_down2[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,517,332\n",
      "Trainable params: 7,517,332\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/300\n",
      "WARNING: AutoGraph could not transform <function SALSA at 0x7fe9cff055e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: \"set_loop_options\" must be the first statement in the loop block\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0056 - custom_mse: 7.0968e-05 - custom_mae: 0.0048\n",
      "Epoch 1: val_loss improved from inf to 0.00583, saving model to unet_model_1D/parts/new_conformer_mic_com_top_001.h5\n",
      "764/764 [==============================] - 614s 783ms/step - loss: 0.0056 - custom_mse: 7.0968e-05 - custom_mae: 0.0048 - val_loss: 0.0058 - val_custom_mse: 7.3849e-05 - val_custom_mae: 0.0046\n",
      "Epoch 2/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0055 - custom_mse: 7.2213e-05 - custom_mae: 0.0049\n",
      "Epoch 2: val_loss improved from 0.00583 to 0.00557, saving model to unet_model_1D/parts/new_conformer_mic_com_top_002.h5\n",
      "764/764 [==============================] - 602s 786ms/step - loss: 0.0055 - custom_mse: 7.2213e-05 - custom_mae: 0.0049 - val_loss: 0.0056 - val_custom_mse: 7.0287e-05 - val_custom_mae: 0.0045\n",
      "Epoch 3/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0055 - custom_mse: 7.4947e-05 - custom_mae: 0.0049\n",
      "Epoch 3: val_loss did not improve from 0.00557\n",
      "764/764 [==============================] - 600s 783ms/step - loss: 0.0055 - custom_mse: 7.4947e-05 - custom_mae: 0.0049 - val_loss: 0.0057 - val_custom_mse: 7.2497e-05 - val_custom_mae: 0.0046\n",
      "Epoch 4/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0055 - custom_mse: 8.1957e-05 - custom_mae: 0.0052\n",
      "Epoch 4: val_loss did not improve from 0.00557\n",
      "764/764 [==============================] - 603s 788ms/step - loss: 0.0055 - custom_mse: 8.1957e-05 - custom_mae: 0.0052 - val_loss: 0.0056 - val_custom_mse: 7.1952e-05 - val_custom_mae: 0.0045\n",
      "Epoch 5/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0054 - custom_mse: 7.1632e-05 - custom_mae: 0.0048\n",
      "Epoch 5: val_loss improved from 0.00557 to 0.00555, saving model to unet_model_1D/parts/new_conformer_mic_com_top_005.h5\n",
      "764/764 [==============================] - 600s 783ms/step - loss: 0.0054 - custom_mse: 7.1632e-05 - custom_mae: 0.0048 - val_loss: 0.0056 - val_custom_mse: 7.4713e-05 - val_custom_mae: 0.0046\n",
      "Epoch 6/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0053 - custom_mse: 7.3030e-05 - custom_mae: 0.0048\n",
      "Epoch 6: val_loss improved from 0.00555 to 0.00550, saving model to unet_model_1D/parts/new_conformer_mic_com_top_006.h5\n",
      "764/764 [==============================] - 602s 785ms/step - loss: 0.0053 - custom_mse: 7.3030e-05 - custom_mae: 0.0048 - val_loss: 0.0055 - val_custom_mse: 7.6899e-05 - val_custom_mae: 0.0047\n",
      "Epoch 7/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0053 - custom_mse: 7.3056e-05 - custom_mae: 0.0048\n",
      "Epoch 7: val_loss did not improve from 0.00550\n",
      "764/764 [==============================] - 602s 786ms/step - loss: 0.0053 - custom_mse: 7.3056e-05 - custom_mae: 0.0048 - val_loss: 0.0057 - val_custom_mse: 8.0962e-05 - val_custom_mae: 0.0048\n",
      "Epoch 8/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0053 - custom_mse: 8.1613e-05 - custom_mae: 0.0052\n",
      "Epoch 8: val_loss improved from 0.00550 to 0.00547, saving model to unet_model_1D/parts/new_conformer_mic_com_top_008.h5\n",
      "764/764 [==============================] - 605s 789ms/step - loss: 0.0053 - custom_mse: 8.1613e-05 - custom_mae: 0.0052 - val_loss: 0.0055 - val_custom_mse: 7.7440e-05 - val_custom_mae: 0.0047\n",
      "Epoch 9/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0053 - custom_mse: 7.4976e-05 - custom_mae: 0.0049\n",
      "Epoch 9: val_loss did not improve from 0.00547\n",
      "764/764 [==============================] - 601s 785ms/step - loss: 0.0053 - custom_mse: 7.4976e-05 - custom_mae: 0.0049 - val_loss: 0.0055 - val_custom_mse: 8.0354e-05 - val_custom_mae: 0.0047\n",
      "Epoch 10/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0052 - custom_mse: 7.5128e-05 - custom_mae: 0.0049\n",
      "Epoch 10: val_loss improved from 0.00547 to 0.00537, saving model to unet_model_1D/parts/new_conformer_mic_com_top_010.h5\n",
      "764/764 [==============================] - 606s 789ms/step - loss: 0.0052 - custom_mse: 7.5128e-05 - custom_mae: 0.0049 - val_loss: 0.0054 - val_custom_mse: 7.8681e-05 - val_custom_mae: 0.0047\n",
      "Epoch 11/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0052 - custom_mse: 7.7068e-05 - custom_mae: 0.0050\n",
      "Epoch 11: val_loss improved from 0.00537 to 0.00524, saving model to unet_model_1D/parts/new_conformer_mic_com_top_011.h5\n",
      "764/764 [==============================] - 611s 796ms/step - loss: 0.0052 - custom_mse: 7.7068e-05 - custom_mae: 0.0050 - val_loss: 0.0052 - val_custom_mse: 7.9858e-05 - val_custom_mae: 0.0048\n",
      "Epoch 12/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0052 - custom_mse: 7.5818e-05 - custom_mae: 0.0049\n",
      "Epoch 12: val_loss did not improve from 0.00524\n",
      "764/764 [==============================] - 602s 786ms/step - loss: 0.0052 - custom_mse: 7.5818e-05 - custom_mae: 0.0049 - val_loss: 0.0054 - val_custom_mse: 8.4195e-05 - val_custom_mae: 0.0049\n",
      "Epoch 13/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0051 - custom_mse: 7.7718e-05 - custom_mae: 0.0050\n",
      "Epoch 13: val_loss did not improve from 0.00524\n",
      "764/764 [==============================] - 603s 788ms/step - loss: 0.0051 - custom_mse: 7.7718e-05 - custom_mae: 0.0050 - val_loss: 0.0054 - val_custom_mse: 8.2431e-05 - val_custom_mae: 0.0048\n",
      "Epoch 14/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0051 - custom_mse: 7.6263e-05 - custom_mae: 0.0049\n",
      "Epoch 14: val_loss did not improve from 0.00524\n",
      "764/764 [==============================] - 602s 783ms/step - loss: 0.0051 - custom_mse: 7.6263e-05 - custom_mae: 0.0049 - val_loss: 0.0054 - val_custom_mse: 8.2018e-05 - val_custom_mae: 0.0048\n",
      "Epoch 15/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0051 - custom_mse: 7.6717e-05 - custom_mae: 0.0049\n",
      "Epoch 15: val_loss improved from 0.00524 to 0.00524, saving model to unet_model_1D/parts/new_conformer_mic_com_top_015.h5\n",
      "764/764 [==============================] - 606s 789ms/step - loss: 0.0051 - custom_mse: 7.6717e-05 - custom_mae: 0.0049 - val_loss: 0.0052 - val_custom_mse: 8.1888e-05 - val_custom_mae: 0.0048\n",
      "Epoch 16/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0050 - custom_mse: 7.7506e-05 - custom_mae: 0.0049\n",
      "Epoch 17: val_loss improved from 0.00521 to 0.00512, saving model to unet_model_1D/parts/new_conformer_mic_com_top_017.h5\n",
      "764/764 [==============================] - 604s 786ms/step - loss: 0.0050 - custom_mse: 7.7506e-05 - custom_mae: 0.0049 - val_loss: 0.0051 - val_custom_mse: 7.9335e-05 - val_custom_mae: 0.0048\n",
      "Epoch 18/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0050 - custom_mse: 8.4082e-05 - custom_mae: 0.0052\n",
      "Epoch 18: val_loss improved from 0.00512 to 0.00506, saving model to unet_model_1D/parts/new_conformer_mic_com_top_018.h5\n",
      "764/764 [==============================] - 604s 786ms/step - loss: 0.0050 - custom_mse: 8.4082e-05 - custom_mae: 0.0052 - val_loss: 0.0051 - val_custom_mse: 8.2861e-05 - val_custom_mae: 0.0048\n",
      "Epoch 19/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0050 - custom_mse: 7.9194e-05 - custom_mae: 0.0050\n",
      "Epoch 19: val_loss did not improve from 0.00506\n",
      "764/764 [==============================] - 604s 786ms/step - loss: 0.0050 - custom_mse: 7.9194e-05 - custom_mae: 0.0050 - val_loss: 0.0051 - val_custom_mse: 8.3149e-05 - val_custom_mae: 0.0049\n",
      "Epoch 20/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0050 - custom_mse: 7.8642e-05 - custom_mae: 0.0050\n",
      "Epoch 20: val_loss improved from 0.00506 to 0.00506, saving model to unet_model_1D/parts/new_conformer_mic_com_top_020.h5\n",
      "764/764 [==============================] - 603s 784ms/step - loss: 0.0050 - custom_mse: 7.8642e-05 - custom_mae: 0.0050 - val_loss: 0.0051 - val_custom_mse: 8.2835e-05 - val_custom_mae: 0.0048\n",
      "Epoch 21/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0050 - custom_mse: 8.0039e-05 - custom_mae: 0.0050\n",
      "Epoch 21: val_loss did not improve from 0.00506\n",
      "764/764 [==============================] - 605s 788ms/step - loss: 0.0050 - custom_mse: 8.0039e-05 - custom_mae: 0.0050 - val_loss: 0.0051 - val_custom_mse: 8.5643e-05 - val_custom_mae: 0.0049\n",
      "Epoch 22/300\n",
      "764/764 [==============================] - ETA: 0s - loss: 0.0050 - custom_mse: 7.9490e-05 - custom_mae: 0.0050\n",
      "Epoch 22: val_loss did not improve from 0.00506\n",
      "764/764 [==============================] - 603s 786ms/step - loss: 0.0050 - custom_mse: 7.9490e-05 - custom_mae: 0.0050 - val_loss: 0.0051 - val_custom_mse: 8.4924e-05 - val_custom_mae: 0.0049\n",
      "Epoch 23/300\n",
      "462/764 [=================>............] - ETA: 3:55 - loss: 0.0048 - custom_mse: 7.8519e-05 - custom_mae: 0.0049"
     ]
    }
   ],
   "source": [
    "# number of vectors for each wave file\n",
    "# train model\n",
    "\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('unet_model_1D/parts/new_conformer_mic_com_top_{epoch:03d}.h5', monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True, save_weights_only=False,\n",
    "                             mode='auto', save_frequency=1)\n",
    "checkpoint2 = keras.callbacks.ModelCheckpoint('unet_model_1D/parts/new_conformer_mic_com_top_{epoch:03d}.h5', period=10) \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Converting sparse IndexedSlices\")\n",
    "initial_learning_rate = 0.00007\n",
    "final_learning_rate = 0.000001\n",
    "learning_rate_decay_factor = (final_learning_rate /initial_learning_rate)**(1/100)\n",
    "steps_per_epoch = int(694)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                initial_learning_rate=initial_learning_rate,\n",
    "                decay_steps=steps_per_epoch,\n",
    "                decay_rate=learning_rate_decay_factor,\n",
    "                staircase=True)\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=455):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "        'd_model': self.d_model,\n",
    "        'warmup_steps': self.warmup_steps,\n",
    "         }\n",
    "        return config\n",
    "\n",
    "    def __call__(self, step):\n",
    "        d_model = tf.cast(self.d_model, tf.float32)\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "\n",
    "# print(\"============== MODEL TRAINING ==============\")\n",
    "model = keras_model_uformer.wave_u_net(num_initial_filters = 64, num_layers = 4, \n",
    "               source_names = [\"siren\"], num_channels = 4, output_filter_size = 1,\n",
    "               padding = \"same\", input_size = 44100, context = False, upsampling_type = \"direct\",\n",
    "               output_activation = \"tanh\", output_type = \"direct\")\n",
    "\n",
    "learning_rate = CustomSchedule(256.)\n",
    "\n",
    "# Load Model\n",
    "model.summary()\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss =\n",
    "              SALSA_loss,\n",
    "              metrics= [custom_mse, custom_mae])\n",
    "\n",
    "# Load Checkpoint\n",
    "\n",
    "history = model.fit(data_train,\n",
    "                    epochs=300,\n",
    "                    verbose=1,\n",
    "                    validation_data = data_val,\n",
    "                    callbacks = [checkpoint,checkpoint2])\n",
    "\n",
    "\n",
    "\n",
    "# print(\"============== END TRAINING ==============\")\n",
    "\n",
    "\n",
    "# # gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
